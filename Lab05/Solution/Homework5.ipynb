{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNf/H8aIPBiwSazNMU9zprm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f1a735d24c694447b14a554ed26d069f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2a4fd59e049e48aa9c5fba6124afa442",
              "IPY_MODEL_72e796f6a9da4d4ba175840dde208b91"
            ],
            "layout": "IPY_MODEL_8c72960a1b4c4f69a8c975a07fb20184"
          }
        },
        "2a4fd59e049e48aa9c5fba6124afa442": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f56992b3bb4e4f35b01a012af6b33faf",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_6fe42d2d80c74b908bfa17c5b4e397ae",
            "value": "0.001 MB of 0.010 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "72e796f6a9da4d4ba175840dde208b91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cfc0244591ca4be09a4138c6004c4d03",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9a054bc44ae94a8f999351af2c50310b",
            "value": 0.11638299895407436
          }
        },
        "8c72960a1b4c4f69a8c975a07fb20184": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f56992b3bb4e4f35b01a012af6b33faf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6fe42d2d80c74b908bfa17c5b4e397ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cfc0244591ca4be09a4138c6004c4d03": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9a054bc44ae94a8f999351af2c50310b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/baranceanuvlad/Advanced-Topics-in-Neural-Networks-Template-2023/blob/main/Lab05/Solution/Homework5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "f_cQDrWMZK55"
      },
      "outputs": [],
      "source": [
        "from multiprocessing import freeze_support\n",
        "\n",
        "import torch\n",
        "from torchvision.datasets import CIFAR10\n",
        "from torchvision.transforms import v2\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from tqdm import tqdm\n",
        "from torch.utils.tensorboard import SummaryWriter"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb"
      ],
      "metadata": {
        "id": "loy_FoGyk8te"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "\n",
        "wandb.login(key=\"d8de0dc8d1a24788568db317fc1c11409ddb2150\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OvCPIbr0lEv2",
        "outputId": "4de10f7e-48d1-42a5-de11-3fe94620dba2"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sweep_config = {\n",
        "    \"method\": \"random\",\n",
        "    \"name\": \"my-sweep\",\n",
        "    \"parameters\": {\n",
        "        \"learning_rate\": {\"min\": 0.001, \"max\": 0.1},\n",
        "        \"batch_size\": {\"values\": [16, 32, 64, 128]},\n",
        "        \"optimizer\": {\"values\": [\"sgd\", \"adam\"]},\n",
        "    },\n",
        "}\n",
        "\n",
        "sweep_id = wandb.sweep(sweep_config)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aQSWmrlqlfCm",
        "outputId": "b4ba0b7b-d81a-4abe-de5e-78b50f4a0996"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Create sweep with ID: pq79aw75\n",
            "Sweep URL: https://wandb.ai/vlapin/uncategorized/sweeps/pq79aw75\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_default_device():\n",
        "    if torch.cuda.is_available():\n",
        "        return torch.device('cuda')\n",
        "        # For multi-gpu workstations, PyTorch will use the first available GPU (cuda:0), unless specified otherwise\n",
        "        # (cuda:1).\n",
        "    if torch.backends.mps.is_available():\n",
        "        return torch.device('mos')\n",
        "    return torch.device('cpu')\n"
      ],
      "metadata": {
        "id": "l1TG5d1kZPop"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CachedDataset(Dataset):\n",
        "    def __init__(self, dataset, cache=True):\n",
        "        if cache:\n",
        "            dataset = tuple([x for x in dataset])\n",
        "        self.dataset = dataset\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        return self.dataset[i]"
      ],
      "metadata": {
        "id": "JZvJZMbZZcT6"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MLP(torch.nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(MLP, self).__init__()\n",
        "        self.fc1 = torch.nn.Linear(input_size, hidden_size)\n",
        "        self.fc2 = torch.nn.Linear(hidden_size, output_size)\n",
        "        self.relu = torch.nn.ReLU(inplace=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.fc2(self.relu(self.fc1(x)))\n",
        "        # x = self.fc1(x)\n",
        "        # x = self.relu(x)\n",
        "        # x = self.fc2(x)\n",
        "        # return x"
      ],
      "metadata": {
        "id": "CrGBKjdcZc9a"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(output, labels):\n",
        "    fp_plus_fn = torch.logical_not(output == labels).sum().item()\n",
        "    all_elements = len(output)\n",
        "    return (all_elements - fp_plus_fn) / all_elements"
      ],
      "metadata": {
        "id": "0g4oEs60ZjOe"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, train_loader, criterion, optimizer, device, writer):\n",
        "    model.train()\n",
        "\n",
        "    all_outputs = []\n",
        "    all_labels = []\n",
        "    batch_number = 0\n",
        "    total_loss = 0\n",
        "\n",
        "    for data, labels in train_loader:\n",
        "        batch_number += 1\n",
        "\n",
        "        data = data.to(device, non_blocking=True)\n",
        "        labels = labels.to(device, non_blocking=True)\n",
        "        output = model(data)\n",
        "        loss = criterion(output, labels)\n",
        "        writer.add_scalar(\"Batch Training/Loss\", batch_number, loss)\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        loss.backward()\n",
        "        # torch.nn.utils.clip_grad_norm_(model.parameters(), 5)\n",
        "\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "\n",
        "        output = output.sigmoid().detach().cpu().squeeze()\n",
        "        labels = labels.cpu().squeeze()\n",
        "        all_outputs.append(output)\n",
        "        all_labels.append(labels)\n",
        "\n",
        "    all_outputs = torch.cat(all_outputs).argmax(dim=1)\n",
        "    all_labels = torch.cat(all_labels)\n",
        "\n",
        "    return round(accuracy(all_outputs, all_labels), 4) , total_loss / len(train_loader)\n"
      ],
      "metadata": {
        "id": "ckacDUyUZw-B"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def val(model, val_loader, criterion, device):\n",
        "    model.eval()\n",
        "\n",
        "    all_outputs = []\n",
        "    all_labels = []\n",
        "    total_loss = 0\n",
        "\n",
        "    for data, labels in val_loader:\n",
        "        data = data.to(device, non_blocking=True)\n",
        "        labels = labels.to(device, non_blocking=True)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            output = model(data)\n",
        "\n",
        "        loss = criterion(output, labels)\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        output = output.sigmoid().cpu().squeeze()\n",
        "        labels = labels.cpu().squeeze().to(torch.bool)\n",
        "        all_outputs.append(output)\n",
        "        all_labels.append(labels)\n",
        "\n",
        "    all_outputs = torch.cat(all_outputs).argmax(dim=1)\n",
        "    all_labels = torch.cat(all_labels).to(torch.bool)\n",
        "\n",
        "    return round(accuracy(all_outputs, all_labels), 4), total_loss / len(val_loader)"
      ],
      "metadata": {
        "id": "ldv6x_LfZzJ8"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def do_epoch(model, train_loader, val_loader, criterion, optimizer, device, writer):\n",
        "    acc, loss = train(model, train_loader, criterion, optimizer, device, writer)\n",
        "    acc_val, loss_val = val(model, val_loader, criterion, device)\n",
        "    # torch.cuda.empty_cache()\n",
        "    return acc, acc_val, loss, loss_val"
      ],
      "metadata": {
        "id": "l_OqVklHZ1v7"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_model_norm(model):\n",
        "    norm = 0.0\n",
        "    for param in model.parameters():\n",
        "        norm += torch.norm(param)\n",
        "    return norm\n"
      ],
      "metadata": {
        "id": "2F-26d1rZ305"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main(device=get_default_device()):\n",
        "    transforms = [\n",
        "        v2.ToImage(),\n",
        "        v2.ToDtype(torch.float32, scale=True),\n",
        "        v2.Resize((28, 28), antialias=True),\n",
        "        v2.Grayscale(),\n",
        "        torch.flatten,\n",
        "    ]\n",
        "\n",
        "\n",
        "\n",
        "    data_path = '../data'\n",
        "    train_dataset = CIFAR10(root=data_path, train=True, transform=v2.Compose(transforms), download=True)\n",
        "    val_dataset = CIFAR10(root=data_path, train=False, transform=v2.Compose(transforms), download=True)\n",
        "    train_dataset = CachedDataset(train_dataset)\n",
        "    val_dataset = CachedDataset(val_dataset)\n",
        "\n",
        "\n",
        "    config = wandb.init()\n",
        "    learning_rate = config.config.parameters.learning_rate\n",
        "    batch_size = config.config.parameters.batch_size\n",
        "    optimizer = config.config.parameters.optimizer\n",
        "\n",
        "    model = MLP(784, 100, 10)\n",
        "    model = model.to(device)\n",
        "    #optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    epochs = 50\n",
        "\n",
        "    #batch_size = 256\n",
        "    val_batch_size = 500\n",
        "    num_workers = 2\n",
        "    persistent_workers = (num_workers != 0)\n",
        "    pin_memory = device.type == 'cuda'\n",
        "    train_loader = DataLoader(train_dataset, shuffle=True, pin_memory=pin_memory, num_workers=num_workers,\n",
        "                              batch_size=batch_size, drop_last=True, persistent_workers=persistent_workers)\n",
        "    val_loader = DataLoader(val_dataset, shuffle=False, pin_memory=True, num_workers=0, batch_size=val_batch_size,\n",
        "                            drop_last=False)\n",
        "\n",
        "    log_dir = \"logs\"\n",
        "    writer = SummaryWriter(log_dir)\n",
        "    writer.add_scalar('Batch size', batch_size)\n",
        "    writer.add_text('Optimizer', optimizer.__class__.__name__)\n",
        "    writer.add_scalar('Learning rate', learning_rate)\n",
        "\n",
        "\n",
        "    tbar = tqdm(tuple(range(epochs)))\n",
        "    for epoch in tbar:\n",
        "        acc, acc_val, loss, loss_val = do_epoch(model, train_loader, val_loader, criterion, optimizer, device, writer)\n",
        "        tbar.set_postfix_str(f\"Acc: {acc}, Acc_val: {acc_val}\")\n",
        "        writer.add_scalar(\"Train/Loss\", loss, epoch)\n",
        "        writer.add_scalar(\"Train/Accuracy\", acc, epoch)\n",
        "        writer.add_scalar(\"Val/Loss\", loss_val, epoch)\n",
        "        writer.add_scalar(\"Val/Accuracy\", acc_val, epoch)\n",
        "        writer.add_scalar(\"Model/Norm\", get_model_norm(model), epoch)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "YvJA27RtaEnK"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "    freeze_support()\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 750,
          "referenced_widgets": [
            "f1a735d24c694447b14a554ed26d069f",
            "2a4fd59e049e48aa9c5fba6124afa442",
            "72e796f6a9da4d4ba175840dde208b91",
            "8c72960a1b4c4f69a8c975a07fb20184",
            "f56992b3bb4e4f35b01a012af6b33faf",
            "6fe42d2d80c74b908bfa17c5b4e397ae",
            "cfc0244591ca4be09a4138c6004c4d03",
            "9a054bc44ae94a8f999351af2c50310b"
          ]
        },
        "id": "5ynZAgXcaG4l",
        "outputId": "864531cc-0749-4d2b-e981-078423caa34d"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Finishing last run (ID:zyttbuh8) before initializing another..."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, maxâ€¦"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f1a735d24c694447b14a554ed26d069f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">happy-hill-5</strong> at: <a href='https://wandb.ai/vlapin/uncategorized/runs/zyttbuh8' target=\"_blank\">https://wandb.ai/vlapin/uncategorized/runs/zyttbuh8</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20231101_160648-zyttbuh8/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Successfully finished last run (ID:zyttbuh8). Initializing new run:<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.15.12"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20231101_160933-wbm9ce6a</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/vlapin/uncategorized/runs/wbm9ce6a' target=\"_blank\">valiant-sun-6</a></strong> to <a href='https://wandb.ai/vlapin/uncategorized' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/vlapin/uncategorized' target=\"_blank\">https://wandb.ai/vlapin/uncategorized</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/vlapin/uncategorized/runs/wbm9ce6a' target=\"_blank\">https://wandb.ai/vlapin/uncategorized/runs/wbm9ce6a</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_config.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mke\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_config.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    129\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_items\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'parameters'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-7b98c651b570>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mfreeze_support\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-31-2d3acbd9f92a>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(device)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mlearning_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_config.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    162\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mke\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m             raise AttributeError(\n\u001b[0m\u001b[1;32m    165\u001b[0m                 \u001b[0;34mf\"{self.__class__!r} object has no attribute {key!r}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m             ) from ke\n",
            "\u001b[0;31mAttributeError\u001b[0m: <class 'wandb.sdk.wandb_config.Config'> object has no attribute 'parameters'"
          ]
        }
      ]
    }
  ]
}