{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/baranceanuvlad/Advanced-Topics-in-Neural-Networks-Template-2023/blob/main/Lab05/Solution/Homework5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f_cQDrWMZK55"
      },
      "outputs": [],
      "source": [
        "from multiprocessing import freeze_support\n",
        "\n",
        "import torch\n",
        "from torchvision.datasets import CIFAR10\n",
        "from torchvision.transforms import v2\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from tqdm import tqdm\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import random\n",
        "import torchvision.transforms as transformss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "quyupK63KJ5M",
        "outputId": "5a8055ec-d4d6-43a1-ee4d-007025abcea2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sam-pytorch in /usr/local/lib/python3.10/dist-packages (0.0.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from sam-pytorch) (2.1.0+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->sam-pytorch) (3.12.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->sam-pytorch) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->sam-pytorch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->sam-pytorch) (3.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->sam-pytorch) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->sam-pytorch) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->sam-pytorch) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->sam-pytorch) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->sam-pytorch) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install sam-pytorch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "loy_FoGyk8te",
        "outputId": "3780abb6-e9b6-4a2a-d9d1-f9655624e78c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (0.15.12)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n",
            "Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.1.40)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.31.0)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.34.0)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.1)\n",
            "Requirement already satisfied: pathtools in /usr/local/lib/python3.10/dist-packages (from wandb) (0.1.2)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb) (1.3.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (67.7.2)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.4.4)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.3.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2023.7.22)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X59Ck2UeKVwv"
      },
      "outputs": [],
      "source": [
        "from sam import SAM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OvCPIbr0lEv2"
      },
      "outputs": [],
      "source": [
        "import wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l1TG5d1kZPop"
      },
      "outputs": [],
      "source": [
        "def get_default_device():\n",
        "    if torch.cuda.is_available():\n",
        "        return torch.device('cuda')\n",
        "        # For multi-gpu workstations, PyTorch will use the first available GPU (cuda:0), unless specified otherwise\n",
        "        # (cuda:1).\n",
        "    if torch.backends.mps.is_available():\n",
        "        return torch.device('mos')\n",
        "    return torch.device('cpu')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JZvJZMbZZcT6"
      },
      "outputs": [],
      "source": [
        "class CachedDataset(Dataset):\n",
        "    def __init__(self, dataset, cache=True):\n",
        "        if cache:\n",
        "            dataset = tuple([x for x in dataset])\n",
        "        self.dataset = dataset\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        return self.dataset[i]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CrGBKjdcZc9a"
      },
      "outputs": [],
      "source": [
        "class MLP(torch.nn.Module):\n",
        "    def __init__(self, input_size, hidden_size_1, hidden_size_2,hidden_size_3,hidden_size_4, output_size):\n",
        "        super(MLP, self).__init__()\n",
        "        self.fc1 = torch.nn.Linear(input_size, hidden_size_1)\n",
        "        self.fc2 = torch.nn.Linear(hidden_size_1, hidden_size_2)\n",
        "        self.fc3 = torch.nn.Linear(hidden_size_2, hidden_size_3)\n",
        "        self.fc4 = torch.nn.Linear(hidden_size_3, hidden_size_4)\n",
        "        self.fc5 = torch.nn.Linear(hidden_size_4, output_size)\n",
        "        self.relu = torch.nn.ReLU(inplace=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.fc5(self.relu(self.fc4(self.relu(self.fc3(self.relu(self.fc2(self.relu(self.fc1(x)))))))))\n",
        "        # x = self.fc1(x)\n",
        "        # x = self.relu(x)\n",
        "        # x = self.fc2(x)\n",
        "        # return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0g4oEs60ZjOe"
      },
      "outputs": [],
      "source": [
        "def accuracy(output, labels):\n",
        "    fp_plus_fn = torch.logical_not(output == labels).sum().item()\n",
        "    all_elements = len(output)\n",
        "    return (all_elements - fp_plus_fn) / all_elements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KUWbyp0fdXN5"
      },
      "outputs": [],
      "source": [
        "def train(model, train_loader, criterion, optimizer, device, writer):\n",
        "    model.train()\n",
        "\n",
        "    all_outputs = []\n",
        "    all_labels = []\n",
        "    batch_number = 0\n",
        "    total_loss = 0\n",
        "\n",
        "    for data, labels in train_loader:\n",
        "        batch_number += 1\n",
        "\n",
        "        data = data.to(device, non_blocking=True)\n",
        "        labels = labels.to(device, non_blocking=True)\n",
        "        #output = model(data)\n",
        "        #loss = criterion(output, labels)\n",
        "        #total_loss += loss.item()\n",
        "\n",
        "        def closure():\n",
        "          optimizer.zero_grad()\n",
        "          output = model(data)\n",
        "          loss = criterion(output, labels)\n",
        "\n",
        "          writer.add_scalar(\"Batch Training/Loss\", batch_number, loss)\n",
        "          loss.backward()\n",
        "          return loss\n",
        "        optimizer.step(closure)\n",
        "\n",
        "        #loss.backward()\n",
        "        # torch.nn.utils.clip_grad_norm_(model.parameters(), 5)\n",
        "\n",
        "        #optimizer.step()\n",
        "        #optimizer.zero_grad(set_to_none=True)\n",
        "        output = model(data)\n",
        "        output = output.softmax(dim=1).detach().cpu().squeeze()\n",
        "        labels = labels.cpu().squeeze()\n",
        "        all_outputs.append(output)\n",
        "        all_labels.append(labels)\n",
        "\n",
        "    all_outputs = torch.cat(all_outputs).argmax(dim=1)\n",
        "    all_labels = torch.cat(all_labels)\n",
        "\n",
        "    return round(accuracy(all_outputs, all_labels), 4) , total_loss / len(train_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ldv6x_LfZzJ8"
      },
      "outputs": [],
      "source": [
        "def val(model, val_loader, criterion, device):\n",
        "    model.eval()\n",
        "\n",
        "    all_outputs = []\n",
        "    all_labels = []\n",
        "    total_loss = 0\n",
        "\n",
        "    for data, labels in val_loader:\n",
        "        data = data.to(device, non_blocking=True)\n",
        "        labels = labels.to(device, non_blocking=True)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            output = model(data)\n",
        "\n",
        "        loss = criterion(output, labels)\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        output = output.softmax(dim=1).cpu().squeeze()\n",
        "        labels = labels.cpu().squeeze()\n",
        "        all_outputs.append(output)\n",
        "        all_labels.append(labels)\n",
        "\n",
        "    all_outputs = torch.cat(all_outputs).argmax(dim=1)\n",
        "    all_labels = torch.cat(all_labels)\n",
        "\n",
        "    return round(accuracy(all_outputs, all_labels), 4), total_loss / len(val_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l_OqVklHZ1v7"
      },
      "outputs": [],
      "source": [
        "def do_epoch(model, train_loader, val_loader, criterion, optimizer, device, writer):\n",
        "    acc, loss = train(model, train_loader, criterion, optimizer, device, writer)\n",
        "    acc_val, loss_val = val(model, val_loader, criterion, device)\n",
        "    # torch.cuda.empty_cache()\n",
        "    return acc, acc_val, loss, loss_val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2F-26d1rZ305"
      },
      "outputs": [],
      "source": [
        "def get_model_norm(model):\n",
        "    norm = 0.0\n",
        "    for param in model.parameters():\n",
        "        norm += torch.norm(param)\n",
        "    return norm\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DLH3drdretqJ"
      },
      "outputs": [],
      "source": [
        "def main_train():\n",
        "    run = wandb.init(\n",
        "        project=\"image-classification\",\n",
        "        notes=\"My first experiment\",\n",
        "    )\n",
        "    device=get_default_device()\n",
        "    learning_rate = wandb.config.learning_rate\n",
        "    batch_size = wandb.config.batch_size\n",
        "    num_epochs = wandb.config.num_epochs\n",
        "\n",
        "    mean = [0.5]  # For grayscale, use a single value for mean\n",
        "    std = [0.5]\n",
        "    transforms = [\n",
        "        v2.ToImage(),\n",
        "        v2.ToDtype(torch.float32, scale=True),\n",
        "        v2.Resize((28, 28), antialias=True),\n",
        "        v2.Grayscale(),\n",
        "        transformss.Normalize(mean, std),\n",
        "        torch.flatten,\n",
        "    ]\n",
        "\n",
        "    data_path = '../data'\n",
        "    train_dataset = CIFAR10(root=data_path, train=True, transform=v2.Compose(transforms), download=True)\n",
        "    val_dataset = CIFAR10(root=data_path, train=False, transform=v2.Compose(transforms), download=True)\n",
        "    train_dataset = CachedDataset(train_dataset)\n",
        "    val_dataset = CachedDataset(val_dataset)\n",
        "\n",
        "    #batch_size = 256\n",
        "    sharpness = 0.1\n",
        "    base_learning_rate = learning_rate\n",
        "    weight_decay = 0.001\n",
        "\n",
        "\n",
        "    val_batch_size = 500\n",
        "    num_workers = 2\n",
        "    persistent_workers = (num_workers != 0)\n",
        "    pin_memory = device.type == 'cuda'\n",
        "    train_loader = DataLoader(train_dataset, shuffle=True, pin_memory=pin_memory, num_workers=num_workers,\n",
        "                              batch_size=batch_size, drop_last=True, persistent_workers=persistent_workers)\n",
        "    val_loader = DataLoader(val_dataset, shuffle=False, pin_memory=True, num_workers=0, batch_size=val_batch_size,\n",
        "                            drop_last=False)\n",
        "\n",
        "    model = MLP(784, 3136, 2000 ,1000, 500, 10)\n",
        "    model = model.to(device)\n",
        "    base_optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
        "    optimizer = SAM(model.parameters(), base_optimizer, rho=sharpness)\n",
        "    param_groups = [{'params': model.parameters()}]\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "    log_dir = \"logs\"\n",
        "    writer = SummaryWriter(log_dir)\n",
        "    writer.add_scalar('Batch size', batch_size)\n",
        "    writer.add_text('Optimizer', optimizer.__class__.__name__)\n",
        "    writer.add_scalar('Learning rate', learning_rate)\n",
        "    writer.add_scalar('Weight decay', weight_decay)\n",
        "\n",
        "    tbar = tqdm(tuple(range(num_epochs)))\n",
        "    for epoch in tbar:\n",
        "        acc, acc_val, loss, loss_val = do_epoch(model, train_loader, val_loader, criterion, optimizer, device, writer)\n",
        "        wandb.log({\"accuracy\": acc_val, \"loss\": loss_val})\n",
        "        tbar.set_postfix_str(f\"Acc: {acc}, Acc_val: {acc_val}\")\n",
        "        writer.add_scalar(\"Train/Loss\", loss, epoch)\n",
        "        writer.add_scalar(\"Train/Accuracy\", acc, epoch)\n",
        "        writer.add_scalar(\"Val/Loss\", loss_val, epoch)\n",
        "        writer.add_scalar(\"Val/Accuracy\", acc_val, epoch)\n",
        "        writer.add_scalar(\"Model/Norm\", get_model_norm(model), epoch)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YvJA27RtaEnK"
      },
      "outputs": [],
      "source": [
        "def main(device=get_default_device()):\n",
        "\n",
        "\n",
        "    #paramaters_dict =  {\"epochs\": 200, \"learning_rate\": 0.01, \"batch_size\":  random.choice([32, 64, 128, 256]), \"optimizer\": \"SGD with SAM\"}\n",
        "\n",
        "    sweep_config = {\n",
        "      'method': 'random',  # You can choose other methods like 'grid', 'bayes', etc.\n",
        "      'project': 'image-classification',\n",
        "      'parameters': {\n",
        "          'learning_rate': {'values': [0.001,0.05, 0.01, 0.1]},\n",
        "          'batch_size': {'values': [32, 64, 128]},\n",
        "          'num_epochs': {'values': [50, 100, 150]},\n",
        "      }\n",
        "    }\n",
        "\n",
        "    #wandb.config = sweep_config['parameters']\n",
        "    #learning_rate = wandb.config['learning_rate']\n",
        "    #batch_size = wandb.config['batch_size']\n",
        "    #epochs = wandb.config['num_epochs']\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    sweep_id = wandb.sweep(sweep_config, project='image-classification')\n",
        "    wandb.agent(sweep_id, function=main_train)\n",
        "\n",
        "    #tbar = tqdm(tuple(range(epochs)))\n",
        "    #for epoch in tbar:\n",
        "     #   acc, acc_val, loss, loss_val = do_epoch(model, train_loader, val_loader, criterion, optimizer, device, writer)\n",
        "      #  wandb.log({\"accuracy\": acc_val, \"loss\": loss_val})\n",
        "       # tbar.set_postfix_str(f\"Acc: {acc}, Acc_val: {acc_val}\")\n",
        "        #writer.add_scalar(\"Train/Loss\", loss, epoch)\n",
        "        #writer.add_scalar(\"Train/Accuracy\", acc, epoch)\n",
        "        #writer.add_scalar(\"Val/Loss\", loss_val, epoch)\n",
        "        #writer.add_scalar(\"Val/Accuracy\", acc_val, epoch)\n",
        "        #writer.add_scalar(\"Model/Norm\", get_model_norm(model), epoch)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "id": "5ynZAgXcaG4l",
        "outputId": "d646d41f-d474-4a2b-d0c0-08c4763ae5fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Create sweep with ID: 144fqq4m\n",
            "Sweep URL: https://wandb.ai/vlapin/image-classification/sweeps/144fqq4m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: vwy054f1 with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_epochs: 100\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mvlapin\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.15.12"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20231106_103128-vwy054f1</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/vlapin/image-classification/runs/vwy054f1' target=\"_blank\">neat-sweep-1</a></strong> to <a href='https://wandb.ai/vlapin/image-classification' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/vlapin/image-classification/sweeps/144fqq4m' target=\"_blank\">https://wandb.ai/vlapin/image-classification/sweeps/144fqq4m</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/vlapin/image-classification' target=\"_blank\">https://wandb.ai/vlapin/image-classification</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View sweep at <a href='https://wandb.ai/vlapin/image-classification/sweeps/144fqq4m' target=\"_blank\">https://wandb.ai/vlapin/image-classification/sweeps/144fqq4m</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/vlapin/image-classification/runs/vwy054f1' target=\"_blank\">https://wandb.ai/vlapin/image-classification/runs/vwy054f1</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ../data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 170498071/170498071 [00:02<00:00, 73692692.47it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ../data/cifar-10-python.tar.gz to ../data\n",
            "Files already downloaded and verified\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 43%|████▎     | 43/100 [3:25:15<4:29:55, 284.14s/it, Acc: 0.3026, Acc_val: 0.3087]"
          ]
        }
      ],
      "source": [
        "if __name__ == '__main__':\n",
        "    freeze_support()\n",
        "    main()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM7obxY77nExstJ7659oxrB",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}