{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import Tensor\n",
    "import numpy as np\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transform\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#MNIST datasets\n",
    "mnist_trainset = datasets.MNIST(root='./data', train=True, download=True, transform=transform.ToTensor())\n",
    "mnist_testset = datasets.MNIST(root='./data', train=False, download=True, transform=transform.ToTensor())\n",
    "\n",
    "len(mnist_testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_perceptron(X: Tensor, W: Tensor, b: Tensor, y_true: Tensor, mu: float):\n",
    "    for input, labels in zip(X, y_true):\n",
    "        x = input.view(1, -1)\n",
    "        #view - reshaping a tensor and preserving no of elems\n",
    "        # x = images.view(images.shape[0], -1)\n",
    "        encoded_label = torch.zeros(10)\n",
    "        encoded_label[labels] = 1\n",
    "        Z = torch.matmul(x, W) + b\n",
    "        Y = 1 / (1 + torch.exp(-Z))\n",
    "        Error = Y - encoded_label\n",
    "        deltaWL : Tensor = Error.t() @ x\n",
    "        deltabL : Tensor = Error\n",
    "        W = W - mu * deltaWL.t()\n",
    "        b = b - mu * deltabL\n",
    "    return W, b\n",
    "\n",
    "def train(trainset):\n",
    "    mnist_trainloader : DataLoader = DataLoader(trainset, batch_size=128, shuffle=True)\n",
    "    W = torch.randn(784, 10)\n",
    "    b = torch.randn(10)\n",
    "    mu = 0.01\n",
    "\n",
    "    X, y_true = None, None\n",
    "    for inputs, labels in mnist_trainloader:\n",
    "        if X is None:\n",
    "            X = inputs.view(inputs.shape[0], -1)\n",
    "            y_true = labels\n",
    "        else:\n",
    "            X = torch.cat((X, inputs.view(inputs.shape[0], -1)), dim=0)\n",
    "            y_true = torch.cat((y_true, labels), dim=0)\n",
    "\n",
    "    return train_perceptron(X, W, b, y_true, mu)\n",
    "       \n",
    "\n",
    "W, b = train(mnist_trainset)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88.75999999999999"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def predict(testset, W, b):\n",
    "    mnist_testloader = torch.utils.data.DataLoader(testset, batch_size=1, shuffle=True)\n",
    "    ok = 0\n",
    "    for images, labels in mnist_testloader:\n",
    "        #view - reshaping a tensor and preserving no of elems\n",
    "        X = images.view(images.shape[0], -1)\n",
    "        y_true = torch.zeros(10)\n",
    "        y_true[labels[0]] = 1\n",
    "        Z = torch.matmul(X, W) + b\n",
    "        Y = 1 / (1 + torch.exp(-Z))\n",
    "        if torch.argmax(y_true) == torch.argmax(Y):\n",
    "            ok += 1\n",
    "        #return Y, y_true, labels\n",
    "    return ok / len(testset) * 100\n",
    "    \n",
    "predict(mnist_testset, W, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
