{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-10-16T19:00:37.705048Z",
     "start_time": "2023-10-16T19:00:37.699138Z"
    }
   },
   "outputs": [],
   "source": [
    "import gzip\n",
    "import pickle\n",
    "import torch\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [],
   "source": [
    "class Model:\n",
    "    LEARNING_RATE = 0.01\n",
    "\n",
    "    def __init__(self, input_dimensions, output_dimensions):\n",
    "        self.input_dimensions = input_dimensions\n",
    "        self.output_dimensions = output_dimensions\n",
    "        self.biases = None  # shape: (1, 10)\n",
    "        self.weights = None  # shape: (784, 10)\n",
    "        self.training_set = None\n",
    "        self.validation_set = None\n",
    "        self.testing_set = None\n",
    "\n",
    "    @staticmethod\n",
    "    def sigmoid(z):\n",
    "        return 1.0 / (1.0 + torch.exp(-z))\n",
    "\n",
    "    def load_input(self):\n",
    "        def _map_data(given_set):\n",
    "            data = given_set[0]\n",
    "            tags = given_set[1]\n",
    "            output = []\n",
    "\n",
    "            for index in range(len(tags)):\n",
    "                output += [(torch.from_numpy(data[index]).view(1, self.input_dimensions), tags[index])]\n",
    "\n",
    "            return output\n",
    "\n",
    "        with gzip.open(\"mnist.pkl.gz\", \"rb\") as fd:\n",
    "            training_set, validation_set, testing_set = pickle.load(fd, encoding='latin')\n",
    "\n",
    "        self.training_set = _map_data(training_set)\n",
    "        self.validation_set = _map_data(validation_set)\n",
    "        self.testing_set = _map_data(testing_set)\n",
    "\n",
    "    def load_params(self):\n",
    "        self.biases = torch.rand(1, self.output_dimensions, dtype=torch.float32)  # 1, 784\n",
    "        self.weights = torch.rand(self.input_dimensions, self.output_dimensions, dtype=torch.float32)  # 784, 10\n",
    "\n",
    "    def train_online(self, data_set, max_iterations, learning_rate):\n",
    "        iterations = max_iterations\n",
    "        all_classified = False\n",
    "\n",
    "        while not all_classified and iterations > 0:\n",
    "            iterations -= 1\n",
    "            all_classified = True\n",
    "            for input_values, correct_tag in tqdm(data_set, unit=\" entries\",\n",
    "                                                  desc=f\"Epoch {max_iterations - iterations}/{max_iterations}\"):\n",
    "                expected_result = torch.tensor([1 if i == correct_tag else 0 for i in range(self.output_dimensions)],\n",
    "                                               dtype=torch.float32)\n",
    "                output = torch.matmul(input_values, self.weights) + self.biases\n",
    "                activated_output = Model.sigmoid(output)\n",
    "\n",
    "                self.weights = self.weights + torch.matmul(input_values.view(self.input_dimensions, 1),\n",
    "                                                           (expected_result - activated_output).view(1,\n",
    "                                                                                                     self.output_dimensions)) * learning_rate\n",
    "                self.biases = self.biases + (expected_result - activated_output) * learning_rate\n",
    "\n",
    "                if not torch.equal(activated_output, expected_result):\n",
    "                    all_classified = False\n",
    "\n",
    "    def train_mini_batch(self, data_set, max_iterations, nr_batches, learning_rate):\n",
    "        iterations = max_iterations\n",
    "        all_classified = False\n",
    "        while not all_classified and iterations > 0:\n",
    "            iterations -= 1\n",
    "            all_classified = True\n",
    "            batch_size = len(data_set) // nr_batches\n",
    "\n",
    "            for batch_index in tqdm(range(nr_batches), unit=\" mini batches\",\n",
    "                                    desc=f\"Epoch {max_iterations - iterations}/{max_iterations}\"):\n",
    "                delta_weights = torch.zeros(self.input_dimensions, self.output_dimensions, dtype=torch.float32)\n",
    "                delta_biases = torch.zeros(self.output_dimensions, dtype=torch.float32)\n",
    "                batch = data_set[batch_index * batch_size: (batch_index + 1) * batch_size]\n",
    "\n",
    "                for input_values, correct_tag in batch:\n",
    "                    expected_result = torch.tensor(\n",
    "                        [1 if i == correct_tag else 0 for i in range(self.output_dimensions)], dtype=torch.float32)\n",
    "                    output = torch.matmul(input_values, self.weights) + self.biases\n",
    "                    activated_output = Model.sigmoid(output)\n",
    "\n",
    "                    delta_weights = delta_weights + torch.matmul(input_values.view(self.input_dimensions, 1),\n",
    "                                                                 (expected_result - activated_output).view(1,\n",
    "                                                                                                           self.output_dimensions)) * learning_rate\n",
    "                    delta_biases = delta_biases + (expected_result - activated_output) * learning_rate\n",
    "\n",
    "                    if not torch.equal(activated_output, expected_result):\n",
    "                        all_classified = False\n",
    "\n",
    "                self.weights += delta_weights\n",
    "                self.biases += delta_biases\n",
    "\n",
    "    def predict(self, input_values):\n",
    "        output = torch.matmul(input_values, self.weights) + self.biases\n",
    "        activated_output = Model.sigmoid(output)\n",
    "        return torch.argmax(activated_output).item()\n",
    "\n",
    "    def test_model(self, data_set):\n",
    "        wrong_predictions = 0\n",
    "        correct_predictions = 0\n",
    "\n",
    "        for input_values, correct_tag in data_set:\n",
    "            predicted_value = self.predict(input_values)\n",
    "            if predicted_value == correct_tag:\n",
    "                correct_predictions += 1\n",
    "            else:\n",
    "                wrong_predictions += 1\n",
    "\n",
    "        print(f\"Correct: {correct_predictions}, \"\n",
    "              f\"Wrong: {wrong_predictions},\"\n",
    "              f\" Total: {correct_predictions + wrong_predictions}, \"\n",
    "              f\"Accuracy: {int(correct_predictions / (correct_predictions + wrong_predictions) * 10000.) / 100}%\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-16T19:00:38.342033Z",
     "start_time": "2023-10-16T19:00:38.339769Z"
    }
   },
   "id": "77153bf497dbf9cb"
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results BEFORE training:\n",
      "Correct: 1002, Wrong: 8998, Total: 10000, Accuracy: 10.02%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|██████████| 50000/50000 [00:01<00:00, 34287.25 entries/s]\n",
      "Epoch 2/10: 100%|██████████| 50000/50000 [00:01<00:00, 34328.02 entries/s]\n",
      "Epoch 3/10: 100%|██████████| 50000/50000 [00:01<00:00, 34298.89 entries/s]\n",
      "Epoch 4/10: 100%|██████████| 50000/50000 [00:01<00:00, 32856.00 entries/s]\n",
      "Epoch 5/10: 100%|██████████| 50000/50000 [00:01<00:00, 32802.79 entries/s]\n",
      "Epoch 6/10: 100%|██████████| 50000/50000 [00:01<00:00, 32802.31 entries/s]\n",
      "Epoch 7/10: 100%|██████████| 50000/50000 [00:01<00:00, 33858.63 entries/s]\n",
      "Epoch 8/10: 100%|██████████| 50000/50000 [00:01<00:00, 34527.43 entries/s]\n",
      "Epoch 9/10: 100%|██████████| 50000/50000 [00:01<00:00, 34495.96 entries/s]\n",
      "Epoch 10/10: 100%|██████████| 50000/50000 [00:01<00:00, 34504.30 entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results on testing set AFTER online training:\n",
      "Correct: 8950, Wrong: 1050, Total: 10000, Accuracy: 89.5%\n",
      "\n",
      "Results on validation set AFTER online training:\n",
      "Correct: 8986, Wrong: 1014, Total: 10000, Accuracy: 89.86%\n"
     ]
    }
   ],
   "source": [
    "model = Model(784, 10)\n",
    "model.load_input()\n",
    "model.load_params()\n",
    "print('Results BEFORE training:')\n",
    "model.test_model(model.testing_set)\n",
    "\n",
    "model.train_online(model.training_set, 10, 0.05)\n",
    "\n",
    "print('Results on testing set AFTER online training:')\n",
    "model.test_model(model.testing_set)\n",
    "\n",
    "print('Results on validation set AFTER online training:')\n",
    "model.test_model(model.validation_set)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-16T19:00:54.827297Z",
     "start_time": "2023-10-16T19:00:38.987185Z"
    }
   },
   "id": "8fa33d595aec075"
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results BEFORE training:\n",
      "Correct: 980, Wrong: 9020, Total: 10000, Accuracy: 9.8%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|██████████| 256/256 [00:01<00:00, 176.57 mini batches/s]\n",
      "Epoch 2/10: 100%|██████████| 256/256 [00:01<00:00, 175.84 mini batches/s]\n",
      "Epoch 3/10: 100%|██████████| 256/256 [00:01<00:00, 175.98 mini batches/s]\n",
      "Epoch 4/10: 100%|██████████| 256/256 [00:01<00:00, 177.24 mini batches/s]\n",
      "Epoch 5/10: 100%|██████████| 256/256 [00:01<00:00, 176.97 mini batches/s]\n",
      "Epoch 6/10: 100%|██████████| 256/256 [00:01<00:00, 177.05 mini batches/s]\n",
      "Epoch 7/10: 100%|██████████| 256/256 [00:01<00:00, 177.23 mini batches/s]\n",
      "Epoch 8/10: 100%|██████████| 256/256 [00:01<00:00, 176.91 mini batches/s]\n",
      "Epoch 9/10: 100%|██████████| 256/256 [00:01<00:00, 177.17 mini batches/s]\n",
      "Epoch 10/10: 100%|██████████| 256/256 [00:01<00:00, 177.12 mini batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results on testing set AFTER mini-batch training:\n",
      "Correct: 9043, Wrong: 957, Total: 10000, Accuracy: 90.43%\n",
      "\n",
      "Results on validation set AFTER mini-batch training:\n",
      "Correct: 9130, Wrong: 870, Total: 10000, Accuracy: 91.3%\n"
     ]
    }
   ],
   "source": [
    "model = Model(784, 10)\n",
    "model.load_input()\n",
    "model.load_params()\n",
    "\n",
    "print('Results BEFORE training:')\n",
    "model.test_model(model.testing_set)\n",
    "\n",
    "model.train_mini_batch(model.training_set, 10, 256, Model.LEARNING_RATE)\n",
    "\n",
    "print('Results on testing set AFTER mini-batch training:')\n",
    "model.test_model(model.testing_set)\n",
    "\n",
    "print('Results on validation set AFTER mini-batch training:')\n",
    "model.test_model(model.validation_set)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-16T19:01:12.334855Z",
     "start_time": "2023-10-16T19:00:56.879197Z"
    }
   },
   "id": "1b78f550e89a7679"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
