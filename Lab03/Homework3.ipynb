{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNCza5Qn37JtVjiC7wN/tzC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/baranceanuvlad/Advanced-Topics-in-Neural-Networks-Template-2023/blob/main/Lab03/Homework3\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "JS_7HKcdcMpM"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch import Tensor\n",
        "from torchvision.datasets import MNIST\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def forward(x: Tensor, w: Tensor, b: Tensor) -> Tensor:\n",
        "    return x @ w + b"
      ],
      "metadata": {
        "id": "8e_2lXarcTFd"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid_function(z):\n",
        "  return 1 / (1 + torch.exp(-z))"
      ],
      "metadata": {
        "id": "c8UsdYlzebQi"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ReLU(z):\n",
        "  return torch.max(z, torch.tensor(0.0))"
      ],
      "metadata": {
        "id": "u6JaytH-VvcI"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ReLU_derivative(x):\n",
        "    return torch.where(x > 0, torch.tensor(1.0), torch.tensor(0.0))"
      ],
      "metadata": {
        "id": "YN9WEeKUWap_"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def activate(x: Tensor) -> Tensor:\n",
        "    return x.softmax(dim=1)"
      ],
      "metadata": {
        "id": "C2VnF1EL6UNK"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_accuracy(prediction, labels):\n",
        "  count = 0\n",
        "  prediction = torch.argmax(prediction, axis=1)\n",
        "  for idx in range(len(prediction)):\n",
        "    if prediction[idx] == labels[idx]:\n",
        "      count += 1\n",
        "  return count * 100 / len(labels)"
      ],
      "metadata": {
        "id": "JvW3ybu3AyMY"
      },
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def collate(x) -> Tensor:\n",
        "    if isinstance(x, (tuple, list)):\n",
        "        if isinstance(x[0], Tensor):\n",
        "            return torch.stack(x)\n",
        "        return torch.tensor(x)\n",
        "    raise \"Not supported yet\"\n",
        "    # see torch\\utils\\data\\_utils\\collate.py"
      ],
      "metadata": {
        "id": "sNbbDOqcdCn2"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def to_one_hot(x: Tensor) -> Tensor:\n",
        "    return torch.eye(x.max() + 1)[x]"
      ],
      "metadata": {
        "id": "ZpWcCl5kdJU6"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_mnist(path: str = \"./data\", train: bool = True, pin_memory: bool = True):\n",
        "    mnist_raw = MNIST(path, download=True, train=train)\n",
        "    mnist_data = []\n",
        "    mnist_labels = []\n",
        "    for image, label in mnist_raw:\n",
        "        tensor = torch.from_numpy(np.array(image))\n",
        "        mnist_data.append(tensor)\n",
        "        mnist_labels.append(label)\n",
        "\n",
        "    mnist_data = collate(mnist_data).float()  # shape 60000, 28, 28\n",
        "    mnist_data = mnist_data.flatten(start_dim=1)  # shape 60000, 784\n",
        "    mnist_data /= mnist_data.max()  # min max normalize\n",
        "    mnist_labels = collate(mnist_labels)  # shape 60000\n",
        "    if train:\n",
        "        mnist_labels = to_one_hot(mnist_labels)  # shape 60000, 10\n",
        "    if False:\n",
        "        return mnist_data.pin_memory(), mnist_labels.pin_memory()\n",
        "    return mnist_data, mnist_labels"
      ],
      "metadata": {
        "id": "xWDr0xhqc1Mp"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data, labels = load_mnist(train=True)\n",
        "data_test, labels_test = load_mnist(train=False)"
      ],
      "metadata": {
        "id": "v4sbq3X_c3kO"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(data.shape, labels.shape)\n",
        "print(data_test.shape, labels.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wOm26v8qeEXC",
        "outputId": "1b71b5be-e263-4597-dfc0-1c3d406ad8ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([60000, 784]) torch.Size([60000, 10])\n",
            "torch.Size([10000, 784]) torch.Size([60000, 10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "W = [torch.rand((784,100)), torch.rand((100,10))]\n",
        "b = [torch.rand(1, 100), torch.rand(1, 10)]\n",
        "learning_rate = 0.07\n",
        "batch_size = 64"
      ],
      "metadata": {
        "id": "RP67ReHLeqtM"
      },
      "execution_count": 165,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def batch_multiplication(a, W, batch_size):\n",
        "  result = torch.zeros(a.shape[0], W.shape[1])\n",
        "  for i in range(0, a.shape[0], batch_size):\n",
        "    aux = a[i: i + batch_size] @ W\n",
        "    result[i : i + batch_size] = aux\n",
        "  return result\n"
      ],
      "metadata": {
        "id": "JEb5MW9tIiXH"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def shuffle_data(a , labels):\n",
        "  num_rows = a.size(0)\n",
        "  random_indices = torch.randperm(num_rows)\n",
        "  return a[random_indices], labels[random_indices]"
      ],
      "metadata": {
        "id": "tKkvvCPhSE-o"
      },
      "execution_count": 156,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train2(data_train, labels, W, b, learning_rate, batch_size):\n",
        "  for _ in range(500):\n",
        "    data_train, labels = shuffle_data(data_train, labels)\n",
        "    z1 = batch_multiplication(data_train, W[0], batch_size) + b[0]\n",
        "    activ1 = ReLU(z1)\n",
        "    z2 = batch_multiplication(activ1, W[1], batch_size) + b[1]\n",
        "    print('Loss Train:', torch.nn.functional.cross_entropy(z2, labels))\n",
        "    activ2 = activate(z2)\n",
        "    print(test_accuracy(activ2, torch.argmax(labels, axis = 1)))\n",
        "\n",
        "    err2 = labels - activ2\n",
        "    err1 = ReLU_derivative(activ1) * (err2  @ W[1].T)\n",
        "    d_w1 = batch_multiplication(data_train.T, err1, batch_size)\n",
        "    d_b1 = err1.mean(axis=0)\n",
        "    d_w2 = batch_multiplication(activ1.T, err2, batch_size)\n",
        "    d_b2 = err2.mean(axis=0)\n",
        "    W[0] += learning_rate * d_w1 / (data_train.shape[0])\n",
        "    b[0] += learning_rate * d_b1\n",
        "    W[1] += learning_rate * d_w2 / (data_train.shape[0])\n",
        "    b[1] += learning_rate * d_b2\n",
        "\n",
        "\n",
        "    z1 = batch_multiplication(data_test, W[0], batch_size) + b[0]\n",
        "    activ1 = ReLU(z1)\n",
        "    z2 = batch_multiplication(activ1, W[1], batch_size) + b[1]\n",
        "    print('Loss Validation:', torch.nn.functional.cross_entropy(z2, labels_test))\n",
        "    activ2 = activate(z2)\n",
        "    print(test_accuracy(activ2, labels_test))\n",
        "\n"
      ],
      "metadata": {
        "id": "vuylnlpfB6UM"
      },
      "execution_count": 159,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train2(data, labels, W, b,learning_rate, batch_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g7UXiAw1kLaR",
        "outputId": "3f0caf56-fd5b-47d0-9724-c9122f0706a0"
      },
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss Train: tensor(184.2829)\n",
            "9.915\n",
            "Loss Validation: tensor(2443.8438)\n",
            "9.8\n",
            "Loss Train: tensor(2364.5713)\n",
            "9.871666666666666\n",
            "Loss Validation: tensor(4580.9014)\n",
            "10.32\n",
            "Loss Train: tensor(4538.6650)\n",
            "9.93\n",
            "Loss Validation: tensor(6415.0098)\n",
            "10.68\n",
            "Loss Train: tensor(6282.0659)\n",
            "11.131666666666666\n",
            "Loss Validation: tensor(7157.5513)\n",
            "9.58\n",
            "Loss Train: tensor(7039.7676)\n",
            "9.863333333333333\n",
            "Loss Validation: tensor(7681.7080)\n",
            "9.74\n",
            "Loss Train: tensor(7558.0630)\n",
            "9.751666666666667\n",
            "Loss Validation: tensor(7511.2646)\n",
            "10.28\n",
            "Loss Train: tensor(7392.8281)\n",
            "10.441666666666666\n",
            "Loss Validation: tensor(6993.1816)\n",
            "9.82\n",
            "Loss Train: tensor(6913.5669)\n",
            "9.736666666666666\n",
            "Loss Validation: tensor(6088.7930)\n",
            "8.92\n",
            "Loss Train: tensor(6026.1680)\n",
            "9.035\n",
            "Loss Validation: tensor(3809.4011)\n",
            "11.35\n",
            "Loss Train: tensor(3780.4099)\n",
            "11.236666666666666\n",
            "Loss Validation: tensor(1024.0638)\n",
            "8.92\n",
            "Loss Train: tensor(1016.0004)\n",
            "9.035\n",
            "Loss Validation: tensor(603.1812)\n",
            "12.79\n",
            "Loss Train: tensor(598.8910)\n",
            "12.483333333333333\n",
            "Loss Validation: tensor(572.8080)\n",
            "9.97\n",
            "Loss Train: tensor(568.4698)\n",
            "10.056666666666667\n",
            "Loss Validation: tensor(618.4448)\n",
            "9.82\n",
            "Loss Train: tensor(620.1748)\n",
            "9.736666666666666\n",
            "Loss Validation: tensor(415.9699)\n",
            "10.86\n",
            "Loss Train: tensor(417.4963)\n",
            "11.29\n",
            "Loss Validation: tensor(387.6758)\n",
            "12.29\n",
            "Loss Train: tensor(392.8913)\n",
            "12.035\n",
            "Loss Validation: tensor(319.1099)\n",
            "11.75\n",
            "Loss Train: tensor(325.2894)\n",
            "11.636666666666667\n",
            "Loss Validation: tensor(271.2163)\n",
            "10.57\n",
            "Loss Train: tensor(280.7121)\n",
            "10.23\n",
            "Loss Validation: tensor(197.9570)\n",
            "10.04\n",
            "Loss Train: tensor(205.3288)\n",
            "10.305\n",
            "Loss Validation: tensor(201.5103)\n",
            "9.9\n",
            "Loss Train: tensor(206.7822)\n",
            "10.008333333333333\n",
            "Loss Validation: tensor(59.1835)\n",
            "15.55\n",
            "Loss Train: tensor(62.1893)\n",
            "14.86\n",
            "Loss Validation: tensor(53.0780)\n",
            "32.03\n",
            "Loss Train: tensor(55.8637)\n",
            "31.49\n",
            "Loss Validation: tensor(51.4731)\n",
            "29.24\n",
            "Loss Train: tensor(54.5148)\n",
            "29.528333333333332\n",
            "Loss Validation: tensor(48.5935)\n",
            "32.62\n",
            "Loss Train: tensor(52.6242)\n",
            "32.403333333333336\n",
            "Loss Validation: tensor(62.7125)\n",
            "31.87\n",
            "Loss Train: tensor(66.7245)\n",
            "32.593333333333334\n",
            "Loss Validation: tensor(55.2394)\n",
            "31.69\n",
            "Loss Train: tensor(58.6594)\n",
            "32.315\n",
            "Loss Validation: tensor(33.6825)\n",
            "29.84\n",
            "Loss Train: tensor(35.6257)\n",
            "29.891666666666666\n",
            "Loss Validation: tensor(29.9653)\n",
            "36.56\n",
            "Loss Train: tensor(32.1100)\n",
            "35.365\n",
            "Loss Validation: tensor(28.1492)\n",
            "42.14\n",
            "Loss Train: tensor(30.1468)\n",
            "41.73166666666667\n",
            "Loss Validation: tensor(22.4455)\n",
            "46.4\n",
            "Loss Train: tensor(24.0474)\n",
            "46.63666666666666\n",
            "Loss Validation: tensor(21.8394)\n",
            "47.58\n",
            "Loss Train: tensor(23.8967)\n",
            "47.9\n",
            "Loss Validation: tensor(19.4592)\n",
            "48.43\n",
            "Loss Train: tensor(21.1591)\n",
            "48.365\n",
            "Loss Validation: tensor(11.5531)\n",
            "57.4\n",
            "Loss Train: tensor(12.8980)\n",
            "57.55833333333333\n",
            "Loss Validation: tensor(8.9429)\n",
            "59.91\n",
            "Loss Train: tensor(10.2177)\n",
            "59.583333333333336\n",
            "Loss Validation: tensor(9.3729)\n",
            "63.3\n",
            "Loss Train: tensor(10.6714)\n",
            "63.23\n",
            "Loss Validation: tensor(7.7155)\n",
            "64.62\n",
            "Loss Train: tensor(8.8879)\n",
            "64.52666666666667\n",
            "Loss Validation: tensor(6.5252)\n",
            "66.81\n",
            "Loss Train: tensor(7.5723)\n",
            "66.77\n",
            "Loss Validation: tensor(6.3921)\n",
            "65.85\n",
            "Loss Train: tensor(7.4238)\n",
            "65.60666666666667\n",
            "Loss Validation: tensor(6.6904)\n",
            "65.19\n",
            "Loss Train: tensor(7.7466)\n",
            "65.15833333333333\n",
            "Loss Validation: tensor(5.7773)\n",
            "67.42\n",
            "Loss Train: tensor(6.7249)\n",
            "67.015\n",
            "Loss Validation: tensor(5.7204)\n",
            "67.78\n",
            "Loss Train: tensor(6.6557)\n",
            "67.43166666666667\n",
            "Loss Validation: tensor(5.6596)\n",
            "67.05\n",
            "Loss Train: tensor(6.5424)\n",
            "67.02333333333333\n",
            "Loss Validation: tensor(5.6612)\n",
            "65.65\n",
            "Loss Train: tensor(6.6219)\n",
            "65.50666666666666\n",
            "Loss Validation: tensor(6.2776)\n",
            "64.85\n",
            "Loss Train: tensor(7.1937)\n",
            "64.76666666666667\n",
            "Loss Validation: tensor(4.8441)\n",
            "68.04\n",
            "Loss Train: tensor(5.7380)\n",
            "67.685\n",
            "Loss Validation: tensor(5.1466)\n",
            "66.85\n",
            "Loss Train: tensor(5.9159)\n",
            "66.63333333333334\n",
            "Loss Validation: tensor(4.3544)\n",
            "68.72\n",
            "Loss Train: tensor(5.0901)\n",
            "68.78166666666667\n",
            "Loss Validation: tensor(4.2815)\n",
            "68.21\n",
            "Loss Train: tensor(5.0077)\n",
            "68.06333333333333\n",
            "Loss Validation: tensor(4.3998)\n",
            "67.72\n",
            "Loss Train: tensor(5.1498)\n",
            "67.46833333333333\n",
            "Loss Validation: tensor(3.8784)\n",
            "68.87\n",
            "Loss Train: tensor(4.5477)\n",
            "68.90166666666667\n",
            "Loss Validation: tensor(3.8466)\n",
            "68.81\n",
            "Loss Train: tensor(4.5049)\n",
            "68.46166666666667\n",
            "Loss Validation: tensor(3.7704)\n",
            "67.78\n",
            "Loss Train: tensor(4.4150)\n",
            "67.62833333333333\n",
            "Loss Validation: tensor(4.1698)\n",
            "66.7\n",
            "Loss Train: tensor(4.8514)\n",
            "66.75666666666666\n",
            "Loss Validation: tensor(3.3812)\n",
            "69.42\n",
            "Loss Train: tensor(3.9551)\n",
            "69.40833333333333\n",
            "Loss Validation: tensor(3.2520)\n",
            "69.31\n",
            "Loss Train: tensor(3.7904)\n",
            "69.375\n",
            "Loss Validation: tensor(3.1580)\n",
            "69.26\n",
            "Loss Train: tensor(3.6925)\n",
            "69.24\n",
            "Loss Validation: tensor(3.1317)\n",
            "69.11\n",
            "Loss Train: tensor(3.6389)\n",
            "68.98333333333333\n",
            "Loss Validation: tensor(3.1675)\n",
            "67.58\n",
            "Loss Train: tensor(3.6970)\n",
            "67.71666666666667\n",
            "Loss Validation: tensor(3.5594)\n",
            "66.58\n",
            "Loss Train: tensor(4.1116)\n",
            "66.64833333333333\n",
            "Loss Validation: tensor(2.9628)\n",
            "68.31\n",
            "Loss Train: tensor(3.4510)\n",
            "68.41666666666667\n",
            "Loss Validation: tensor(2.9626)\n",
            "68.26\n",
            "Loss Train: tensor(3.4051)\n",
            "68.28666666666666\n",
            "Loss Validation: tensor(2.9864)\n",
            "66.7\n",
            "Loss Train: tensor(3.4663)\n",
            "66.96\n",
            "Loss Validation: tensor(3.3861)\n",
            "66.04\n",
            "Loss Train: tensor(3.8779)\n",
            "66.275\n",
            "Loss Validation: tensor(2.7239)\n",
            "68.32\n",
            "Loss Train: tensor(3.1618)\n",
            "68.34166666666667\n",
            "Loss Validation: tensor(2.7567)\n",
            "68.07\n",
            "Loss Train: tensor(3.1375)\n",
            "68.08833333333334\n",
            "Loss Validation: tensor(2.7389)\n",
            "66.97\n",
            "Loss Train: tensor(3.1561)\n",
            "67.12833333333333\n",
            "Loss Validation: tensor(3.0674)\n",
            "66.46\n",
            "Loss Train: tensor(3.4933)\n",
            "66.57666666666667\n",
            "Loss Validation: tensor(2.5293)\n",
            "68.2\n",
            "Loss Train: tensor(2.9165)\n",
            "68.17666666666666\n",
            "Loss Validation: tensor(2.6005)\n",
            "68.15\n",
            "Loss Train: tensor(2.9405)\n",
            "67.94166666666666\n",
            "Loss Validation: tensor(2.5533)\n",
            "67.09\n",
            "Loss Train: tensor(2.9250)\n",
            "67.19666666666667\n",
            "Loss Validation: tensor(2.8705)\n",
            "66.76\n",
            "Loss Train: tensor(3.2520)\n",
            "66.86166666666666\n",
            "Loss Validation: tensor(2.3050)\n",
            "68.85\n",
            "Loss Train: tensor(2.6426)\n",
            "68.665\n",
            "Loss Validation: tensor(2.3450)\n",
            "68.87\n",
            "Loss Train: tensor(2.6354)\n",
            "68.65833333333333\n",
            "Loss Validation: tensor(2.3213)\n",
            "67.91\n",
            "Loss Train: tensor(2.6447)\n",
            "67.83166666666666\n",
            "Loss Validation: tensor(2.6182)\n",
            "67.77\n",
            "Loss Train: tensor(2.9546)\n",
            "67.59166666666667\n",
            "Loss Validation: tensor(2.1201)\n",
            "69.45\n",
            "Loss Train: tensor(2.4137)\n",
            "69.275\n",
            "Loss Validation: tensor(2.1582)\n",
            "69.62\n",
            "Loss Train: tensor(2.4120)\n",
            "69.34833333333333\n",
            "Loss Validation: tensor(2.1340)\n",
            "68.65\n",
            "Loss Train: tensor(2.4161)\n",
            "68.52333333333333\n",
            "Loss Validation: tensor(2.4092)\n",
            "68.53\n",
            "Loss Train: tensor(2.7052)\n",
            "68.395\n",
            "Loss Validation: tensor(1.9641)\n",
            "70.24\n",
            "Loss Train: tensor(2.2192)\n",
            "69.89333333333333\n",
            "Loss Validation: tensor(2.0038)\n",
            "70.37\n",
            "Loss Train: tensor(2.2250)\n",
            "70.06333333333333\n",
            "Loss Validation: tensor(1.9813)\n",
            "69.38\n",
            "Loss Train: tensor(2.2279)\n",
            "69.28833333333333\n",
            "Loss Validation: tensor(2.2361)\n",
            "69.55\n",
            "Loss Train: tensor(2.4958)\n",
            "69.16333333333333\n",
            "Loss Validation: tensor(1.8408)\n",
            "71.0\n",
            "Loss Train: tensor(2.0649)\n",
            "70.52666666666667\n",
            "Loss Validation: tensor(1.8905)\n",
            "71.19\n",
            "Loss Train: tensor(2.0850)\n",
            "70.70666666666666\n",
            "Loss Validation: tensor(1.8592)\n",
            "70.27\n",
            "Loss Train: tensor(2.0766)\n",
            "70.035\n",
            "Loss Validation: tensor(2.0947)\n",
            "70.53\n",
            "Loss Train: tensor(2.3233)\n",
            "69.94\n",
            "Loss Validation: tensor(1.7407)\n",
            "71.73\n",
            "Loss Train: tensor(1.9390)\n",
            "71.15\n",
            "Loss Validation: tensor(1.8005)\n",
            "71.95\n",
            "Loss Train: tensor(1.9723)\n",
            "71.28\n",
            "Loss Validation: tensor(1.7589)\n",
            "71.29\n",
            "Loss Train: tensor(1.9524)\n",
            "70.86166666666666\n",
            "Loss Validation: tensor(1.9772)\n",
            "71.39\n",
            "Loss Train: tensor(2.1790)\n",
            "70.66833333333334\n",
            "Loss Validation: tensor(1.6592)\n",
            "72.44\n",
            "Loss Train: tensor(1.8365)\n",
            "71.80166666666666\n",
            "Loss Validation: tensor(1.7278)\n",
            "72.59\n",
            "Loss Train: tensor(1.8810)\n",
            "71.92\n",
            "Loss Validation: tensor(1.6764)\n",
            "71.93\n",
            "Loss Train: tensor(1.8500)\n",
            "71.52666666666667\n",
            "Loss Validation: tensor(1.8789)\n",
            "71.97\n",
            "Loss Train: tensor(2.0582)\n",
            "71.41166666666666\n",
            "Loss Validation: tensor(1.5929)\n",
            "72.92\n",
            "Loss Train: tensor(1.7529)\n",
            "72.38833333333334\n",
            "Loss Validation: tensor(1.6682)\n",
            "73.08\n",
            "Loss Train: tensor(1.8062)\n",
            "72.54166666666667\n",
            "Loss Validation: tensor(1.6076)\n",
            "72.59\n",
            "Loss Train: tensor(1.7653)\n",
            "72.25666666666666\n",
            "Loss Validation: tensor(1.7961)\n",
            "72.74\n",
            "Loss Train: tensor(1.9572)\n",
            "72.12666666666667\n",
            "Loss Validation: tensor(1.5372)\n",
            "73.53\n",
            "Loss Train: tensor(1.6837)\n",
            "72.98666666666666\n",
            "Loss Validation: tensor(1.6173)\n",
            "73.73\n",
            "Loss Train: tensor(1.7441)\n",
            "73.075\n",
            "Loss Validation: tensor(1.5498)\n",
            "73.19\n",
            "Loss Train: tensor(1.6950)\n",
            "72.83833333333334\n",
            "Loss Validation: tensor(1.7260)\n",
            "73.36\n",
            "Loss Train: tensor(1.8730)\n",
            "72.64333333333333\n",
            "Loss Validation: tensor(1.4903)\n",
            "74.04\n",
            "Loss Train: tensor(1.6263)\n",
            "73.47\n",
            "Loss Validation: tensor(1.5746)\n",
            "74.12\n",
            "Loss Train: tensor(1.6927)\n",
            "73.525\n",
            "Loss Validation: tensor(1.5009)\n",
            "73.8\n",
            "Loss Train: tensor(1.6359)\n",
            "73.35\n",
            "Loss Validation: tensor(1.6667)\n",
            "73.93\n",
            "Loss Train: tensor(1.8021)\n",
            "73.24\n",
            "Loss Validation: tensor(1.4505)\n",
            "74.61\n",
            "Loss Train: tensor(1.5776)\n",
            "73.91166666666666\n",
            "Loss Validation: tensor(1.5379)\n",
            "74.57\n",
            "Loss Train: tensor(1.6489)\n",
            "73.99666666666667\n",
            "Loss Validation: tensor(1.4597)\n",
            "74.31\n",
            "Loss Train: tensor(1.5861)\n",
            "73.80166666666666\n",
            "Loss Validation: tensor(1.6167)\n",
            "74.45\n",
            "Loss Train: tensor(1.7423)\n",
            "73.73\n",
            "Loss Validation: tensor(1.4168)\n",
            "74.97\n",
            "Loss Train: tensor(1.5363)\n",
            "74.32\n",
            "Loss Validation: tensor(1.5068)\n",
            "75.01\n",
            "Loss Train: tensor(1.6115)\n",
            "74.32166666666667\n",
            "Loss Validation: tensor(1.4245)\n",
            "74.83\n",
            "Loss Train: tensor(1.5434)\n",
            "74.22\n",
            "Loss Validation: tensor(1.5740)\n",
            "74.78\n",
            "Loss Train: tensor(1.6911)\n",
            "74.105\n",
            "Loss Validation: tensor(1.3878)\n",
            "75.42\n",
            "Loss Train: tensor(1.5006)\n",
            "74.725\n",
            "Loss Validation: tensor(1.4800)\n",
            "75.34\n",
            "Loss Train: tensor(1.5792)\n",
            "74.655\n",
            "Loss Validation: tensor(1.3941)\n",
            "75.27\n",
            "Loss Train: tensor(1.5061)\n",
            "74.63\n",
            "Loss Validation: tensor(1.5372)\n",
            "75.24\n",
            "Loss Train: tensor(1.6468)\n",
            "74.54166666666667\n",
            "Loss Validation: tensor(1.3623)\n",
            "75.65\n",
            "Loss Train: tensor(1.4689)\n",
            "75.04833333333333\n",
            "Loss Validation: tensor(1.4558)\n",
            "75.67\n",
            "Loss Train: tensor(1.5498)\n",
            "74.985\n",
            "Loss Validation: tensor(1.3672)\n",
            "75.51\n",
            "Loss Train: tensor(1.4730)\n",
            "75.025\n",
            "Loss Validation: tensor(1.5045)\n",
            "75.53\n",
            "Loss Train: tensor(1.6074)\n",
            "74.85166666666667\n",
            "Loss Validation: tensor(1.3393)\n",
            "75.99\n",
            "Loss Train: tensor(1.4403)\n",
            "75.29833333333333\n",
            "Loss Validation: tensor(1.4336)\n",
            "75.98\n",
            "Loss Train: tensor(1.5231)\n",
            "75.26\n",
            "Loss Validation: tensor(1.3428)\n",
            "75.89\n",
            "Loss Train: tensor(1.4430)\n",
            "75.29166666666667\n",
            "Loss Validation: tensor(1.4748)\n",
            "75.87\n",
            "Loss Train: tensor(1.5718)\n",
            "75.15666666666667\n",
            "Loss Validation: tensor(1.3184)\n",
            "76.21\n",
            "Loss Train: tensor(1.4144)\n",
            "75.61166666666666\n",
            "Loss Validation: tensor(1.4137)\n",
            "76.26\n",
            "Loss Train: tensor(1.4991)\n",
            "75.53\n",
            "Loss Validation: tensor(1.3206)\n",
            "76.22\n",
            "Loss Train: tensor(1.4158)\n",
            "75.56333333333333\n",
            "Loss Validation: tensor(1.4478)\n",
            "76.08\n",
            "Loss Train: tensor(1.5394)\n",
            "75.43166666666667\n",
            "Loss Validation: tensor(1.2994)\n",
            "76.39\n",
            "Loss Train: tensor(1.3910)\n",
            "75.84666666666666\n",
            "Loss Validation: tensor(1.3955)\n",
            "76.43\n",
            "Loss Train: tensor(1.4775)\n",
            "75.76\n",
            "Loss Validation: tensor(1.3002)\n",
            "76.5\n",
            "Loss Train: tensor(1.3910)\n",
            "75.85833333333333\n",
            "Loss Validation: tensor(1.4228)\n",
            "76.37\n",
            "Loss Train: tensor(1.5097)\n",
            "75.72\n",
            "Loss Validation: tensor(1.2818)\n",
            "76.62\n",
            "Loss Train: tensor(1.3695)\n",
            "76.08666666666667\n",
            "Loss Validation: tensor(1.3788)\n",
            "76.6\n",
            "Loss Train: tensor(1.4576)\n",
            "76.01166666666667\n",
            "Loss Validation: tensor(1.2812)\n",
            "76.73\n",
            "Loss Train: tensor(1.3681)\n",
            "76.115\n",
            "Loss Validation: tensor(1.3995)\n",
            "76.52\n",
            "Loss Train: tensor(1.4822)\n",
            "75.97333333333333\n",
            "Loss Validation: tensor(1.2653)\n",
            "76.82\n",
            "Loss Train: tensor(1.3496)\n",
            "76.34333333333333\n",
            "Loss Validation: tensor(1.3630)\n",
            "76.78\n",
            "Loss Train: tensor(1.4391)\n",
            "76.23666666666666\n",
            "Loss Validation: tensor(1.2634)\n",
            "76.88\n",
            "Loss Train: tensor(1.3468)\n",
            "76.375\n",
            "Loss Validation: tensor(1.3776)\n",
            "76.73\n",
            "Loss Train: tensor(1.4566)\n",
            "76.25333333333333\n",
            "Loss Validation: tensor(1.2498)\n",
            "76.97\n",
            "Loss Train: tensor(1.3310)\n",
            "76.58666666666667\n",
            "Loss Validation: tensor(1.3479)\n",
            "76.94\n",
            "Loss Train: tensor(1.4215)\n",
            "76.49333333333334\n",
            "Loss Validation: tensor(1.2466)\n",
            "77.09\n",
            "Loss Train: tensor(1.3270)\n",
            "76.62833333333333\n",
            "Loss Validation: tensor(1.3571)\n",
            "76.95\n",
            "Loss Train: tensor(1.4326)\n",
            "76.51\n",
            "Loss Validation: tensor(1.2350)\n",
            "77.25\n",
            "Loss Train: tensor(1.3135)\n",
            "76.84333333333333\n",
            "Loss Validation: tensor(1.3333)\n",
            "77.14\n",
            "Loss Train: tensor(1.4046)\n",
            "76.71833333333333\n",
            "Loss Validation: tensor(1.2308)\n",
            "77.33\n",
            "Loss Train: tensor(1.3085)\n",
            "76.94166666666666\n",
            "Loss Validation: tensor(1.3378)\n",
            "77.17\n",
            "Loss Train: tensor(1.4102)\n",
            "76.77666666666667\n",
            "Loss Validation: tensor(1.2208)\n",
            "77.43\n",
            "Loss Train: tensor(1.2969)\n",
            "77.10166666666667\n",
            "Loss Validation: tensor(1.3190)\n",
            "77.35\n",
            "Loss Train: tensor(1.3883)\n",
            "76.95666666666666\n",
            "Loss Validation: tensor(1.2159)\n",
            "77.53\n",
            "Loss Train: tensor(1.2910)\n",
            "77.16166666666666\n",
            "Loss Validation: tensor(1.3197)\n",
            "77.43\n",
            "Loss Train: tensor(1.3895)\n",
            "77.00333333333333\n",
            "Loss Validation: tensor(1.2072)\n",
            "77.68\n",
            "Loss Train: tensor(1.2810)\n",
            "77.29166666666667\n",
            "Loss Validation: tensor(1.3051)\n",
            "77.48\n",
            "Loss Train: tensor(1.3724)\n",
            "77.13166666666666\n",
            "Loss Validation: tensor(1.2018)\n",
            "77.82\n",
            "Loss Train: tensor(1.2747)\n",
            "77.38833333333334\n",
            "Loss Validation: tensor(1.3030)\n",
            "77.57\n",
            "Loss Train: tensor(1.3703)\n",
            "77.19666666666667\n",
            "Loss Validation: tensor(1.1941)\n",
            "77.94\n",
            "Loss Train: tensor(1.2658)\n",
            "77.52666666666667\n",
            "Loss Validation: tensor(1.2913)\n",
            "77.59\n",
            "Loss Train: tensor(1.3569)\n",
            "77.33166666666666\n",
            "Loss Validation: tensor(1.1884)\n",
            "78.06\n",
            "Loss Train: tensor(1.2592)\n",
            "77.59166666666667\n",
            "Loss Validation: tensor(1.2874)\n",
            "77.72\n",
            "Loss Train: tensor(1.3526)\n",
            "77.44166666666666\n",
            "Loss Validation: tensor(1.1815)\n",
            "78.15\n",
            "Loss Train: tensor(1.2512)\n",
            "77.70833333333333\n",
            "Loss Validation: tensor(1.2778)\n",
            "77.84\n",
            "Loss Train: tensor(1.3417)\n",
            "77.53833333333333\n",
            "Loss Validation: tensor(1.1757)\n",
            "78.26\n",
            "Loss Train: tensor(1.2446)\n",
            "77.80666666666667\n",
            "Loss Validation: tensor(1.2727)\n",
            "77.94\n",
            "Loss Train: tensor(1.3361)\n",
            "77.62833333333333\n",
            "Loss Validation: tensor(1.1693)\n",
            "78.39\n",
            "Loss Train: tensor(1.2372)\n",
            "77.9\n",
            "Loss Validation: tensor(1.2645)\n",
            "78.06\n",
            "Loss Train: tensor(1.3269)\n",
            "77.74833333333333\n",
            "Loss Validation: tensor(1.1635)\n",
            "78.56\n",
            "Loss Train: tensor(1.2306)\n",
            "77.99333333333334\n",
            "Loss Validation: tensor(1.2588)\n",
            "78.12\n",
            "Loss Train: tensor(1.3206)\n",
            "77.84166666666667\n",
            "Loss Validation: tensor(1.1575)\n",
            "78.66\n",
            "Loss Train: tensor(1.2238)\n",
            "78.10666666666667\n",
            "Loss Validation: tensor(1.2516)\n",
            "78.23\n",
            "Loss Train: tensor(1.3125)\n",
            "77.93833333333333\n",
            "Loss Validation: tensor(1.1519)\n",
            "78.7\n",
            "Loss Train: tensor(1.2174)\n",
            "78.20333333333333\n",
            "Loss Validation: tensor(1.2456)\n",
            "78.27\n",
            "Loss Train: tensor(1.3059)\n",
            "78.03666666666666\n",
            "Loss Validation: tensor(1.1461)\n",
            "78.77\n",
            "Loss Train: tensor(1.2109)\n",
            "78.30333333333333\n",
            "Loss Validation: tensor(1.2390)\n",
            "78.34\n",
            "Loss Train: tensor(1.2985)\n",
            "78.12833333333333\n",
            "Loss Validation: tensor(1.1406)\n",
            "78.84\n",
            "Loss Train: tensor(1.2046)\n",
            "78.41333333333333\n",
            "Loss Validation: tensor(1.2330)\n",
            "78.52\n",
            "Loss Train: tensor(1.2920)\n",
            "78.24\n",
            "Loss Validation: tensor(1.1351)\n",
            "78.92\n",
            "Loss Train: tensor(1.1984)\n",
            "78.52\n",
            "Loss Validation: tensor(1.2268)\n",
            "78.62\n",
            "Loss Train: tensor(1.2851)\n",
            "78.36666666666666\n",
            "Loss Validation: tensor(1.1298)\n",
            "78.97\n",
            "Loss Train: tensor(1.1924)\n",
            "78.61666666666666\n",
            "Loss Validation: tensor(1.2210)\n",
            "78.69\n",
            "Loss Train: tensor(1.2787)\n",
            "78.455\n",
            "Loss Validation: tensor(1.1245)\n",
            "79.07\n",
            "Loss Train: tensor(1.1865)\n",
            "78.71166666666667\n",
            "Loss Validation: tensor(1.2151)\n",
            "78.8\n",
            "Loss Train: tensor(1.2721)\n",
            "78.555\n",
            "Loss Validation: tensor(1.1194)\n",
            "79.19\n",
            "Loss Train: tensor(1.1807)\n",
            "78.79166666666667\n",
            "Loss Validation: tensor(1.2094)\n",
            "78.91\n",
            "Loss Train: tensor(1.2659)\n",
            "78.635\n",
            "Loss Validation: tensor(1.1142)\n",
            "79.25\n",
            "Loss Train: tensor(1.1749)\n",
            "78.86833333333334\n",
            "Loss Validation: tensor(1.2038)\n",
            "79.05\n",
            "Loss Train: tensor(1.2596)\n",
            "78.73833333333333\n",
            "Loss Validation: tensor(1.1092)\n",
            "79.38\n",
            "Loss Train: tensor(1.1693)\n",
            "78.95\n",
            "Loss Validation: tensor(1.1983)\n",
            "79.11\n",
            "Loss Train: tensor(1.2536)\n",
            "78.82333333333334\n",
            "Loss Validation: tensor(1.1042)\n",
            "79.42\n",
            "Loss Train: tensor(1.1638)\n",
            "79.06\n",
            "Loss Validation: tensor(1.1929)\n",
            "79.17\n",
            "Loss Train: tensor(1.2476)\n",
            "78.91\n",
            "Loss Validation: tensor(1.0993)\n",
            "79.58\n",
            "Loss Train: tensor(1.1583)\n",
            "79.135\n",
            "Loss Validation: tensor(1.1875)\n",
            "79.32\n",
            "Loss Train: tensor(1.2418)\n",
            "78.99666666666667\n",
            "Loss Validation: tensor(1.0945)\n",
            "79.68\n",
            "Loss Train: tensor(1.1530)\n",
            "79.225\n",
            "Loss Validation: tensor(1.1823)\n",
            "79.42\n",
            "Loss Train: tensor(1.2360)\n",
            "79.09333333333333\n",
            "Loss Validation: tensor(1.0897)\n",
            "79.75\n",
            "Loss Train: tensor(1.1477)\n",
            "79.34\n",
            "Loss Validation: tensor(1.1771)\n",
            "79.49\n",
            "Loss Train: tensor(1.2303)\n",
            "79.18666666666667\n",
            "Loss Validation: tensor(1.0850)\n",
            "79.82\n",
            "Loss Train: tensor(1.1425)\n",
            "79.42166666666667\n",
            "Loss Validation: tensor(1.1720)\n",
            "79.56\n",
            "Loss Train: tensor(1.2247)\n",
            "79.24833333333333\n",
            "Loss Validation: tensor(1.0804)\n",
            "79.91\n",
            "Loss Train: tensor(1.1374)\n",
            "79.51\n",
            "Loss Validation: tensor(1.1670)\n",
            "79.6\n",
            "Loss Train: tensor(1.2193)\n",
            "79.31833333333333\n",
            "Loss Validation: tensor(1.0758)\n",
            "79.97\n",
            "Loss Train: tensor(1.1324)\n",
            "79.61\n",
            "Loss Validation: tensor(1.1620)\n",
            "79.7\n",
            "Loss Train: tensor(1.2138)\n",
            "79.40166666666667\n",
            "Loss Validation: tensor(1.0713)\n",
            "80.09\n",
            "Loss Train: tensor(1.1274)\n",
            "79.68833333333333\n",
            "Loss Validation: tensor(1.1572)\n",
            "79.75\n",
            "Loss Train: tensor(1.2085)\n",
            "79.47333333333333\n",
            "Loss Validation: tensor(1.0668)\n",
            "80.12\n",
            "Loss Train: tensor(1.1225)\n",
            "79.75333333333333\n",
            "Loss Validation: tensor(1.1523)\n",
            "79.87\n",
            "Loss Train: tensor(1.2033)\n",
            "79.55666666666667\n",
            "Loss Validation: tensor(1.0624)\n",
            "80.18\n",
            "Loss Train: tensor(1.1177)\n",
            "79.83333333333333\n",
            "Loss Validation: tensor(1.1476)\n",
            "79.96\n",
            "Loss Train: tensor(1.1981)\n",
            "79.625\n",
            "Loss Validation: tensor(1.0581)\n",
            "80.21\n",
            "Loss Train: tensor(1.1129)\n",
            "79.90166666666667\n",
            "Loss Validation: tensor(1.1429)\n",
            "80.06\n",
            "Loss Train: tensor(1.1930)\n",
            "79.71\n",
            "Loss Validation: tensor(1.0538)\n",
            "80.37\n",
            "Loss Train: tensor(1.1082)\n",
            "79.98666666666666\n",
            "Loss Validation: tensor(1.1383)\n",
            "80.16\n",
            "Loss Train: tensor(1.1880)\n",
            "79.78833333333333\n",
            "Loss Validation: tensor(1.0496)\n",
            "80.41\n",
            "Loss Train: tensor(1.1036)\n",
            "80.03833333333333\n",
            "Loss Validation: tensor(1.1337)\n",
            "80.18\n",
            "Loss Train: tensor(1.1831)\n",
            "79.85666666666667\n",
            "Loss Validation: tensor(1.0454)\n",
            "80.54\n",
            "Loss Train: tensor(1.0990)\n",
            "80.11\n",
            "Loss Validation: tensor(1.1292)\n",
            "80.28\n",
            "Loss Train: tensor(1.1782)\n",
            "79.925\n",
            "Loss Validation: tensor(1.0413)\n",
            "80.66\n",
            "Loss Train: tensor(1.0945)\n",
            "80.18166666666667\n",
            "Loss Validation: tensor(1.1247)\n",
            "80.4\n",
            "Loss Train: tensor(1.1734)\n",
            "80.00333333333333\n",
            "Loss Validation: tensor(1.0372)\n",
            "80.73\n",
            "Loss Train: tensor(1.0901)\n",
            "80.26666666666667\n",
            "Loss Validation: tensor(1.1203)\n",
            "80.47\n",
            "Loss Train: tensor(1.1686)\n",
            "80.06333333333333\n",
            "Loss Validation: tensor(1.0332)\n",
            "80.8\n",
            "Loss Train: tensor(1.0857)\n",
            "80.35333333333334\n",
            "Loss Validation: tensor(1.1159)\n",
            "80.56\n",
            "Loss Train: tensor(1.1640)\n",
            "80.14833333333333\n",
            "Loss Validation: tensor(1.0291)\n",
            "80.87\n",
            "Loss Train: tensor(1.0814)\n",
            "80.43333333333334\n",
            "Loss Validation: tensor(1.1116)\n",
            "80.65\n",
            "Loss Train: tensor(1.1593)\n",
            "80.225\n",
            "Loss Validation: tensor(1.0252)\n",
            "80.94\n",
            "Loss Train: tensor(1.0771)\n",
            "80.49833333333333\n",
            "Loss Validation: tensor(1.1073)\n",
            "80.74\n",
            "Loss Train: tensor(1.1548)\n",
            "80.30833333333334\n",
            "Loss Validation: tensor(1.0213)\n",
            "81.01\n",
            "Loss Train: tensor(1.0729)\n",
            "80.56166666666667\n",
            "Loss Validation: tensor(1.1031)\n",
            "80.76\n",
            "Loss Train: tensor(1.1502)\n",
            "80.36833333333334\n",
            "Loss Validation: tensor(1.0174)\n",
            "81.07\n",
            "Loss Train: tensor(1.0687)\n",
            "80.62666666666667\n",
            "Loss Validation: tensor(1.0989)\n",
            "80.84\n",
            "Loss Train: tensor(1.1458)\n",
            "80.43833333333333\n",
            "Loss Validation: tensor(1.0136)\n",
            "81.09\n",
            "Loss Train: tensor(1.0646)\n",
            "80.7\n",
            "Loss Validation: tensor(1.0947)\n",
            "80.9\n",
            "Loss Train: tensor(1.1414)\n",
            "80.50833333333334\n",
            "Loss Validation: tensor(1.0098)\n",
            "81.15\n",
            "Loss Train: tensor(1.0605)\n",
            "80.77833333333334\n",
            "Loss Validation: tensor(1.0907)\n",
            "80.96\n",
            "Loss Train: tensor(1.1371)\n",
            "80.565\n",
            "Loss Validation: tensor(1.0060)\n",
            "81.27\n",
            "Loss Train: tensor(1.0565)\n",
            "80.84\n",
            "Loss Validation: tensor(1.0866)\n",
            "80.99\n",
            "Loss Train: tensor(1.1328)\n",
            "80.65166666666667\n",
            "Loss Validation: tensor(1.0023)\n",
            "81.36\n",
            "Loss Train: tensor(1.0525)\n",
            "80.90166666666667\n",
            "Loss Validation: tensor(1.0826)\n",
            "81.04\n",
            "Loss Train: tensor(1.1286)\n",
            "80.71166666666667\n",
            "Loss Validation: tensor(0.9987)\n",
            "81.36\n",
            "Loss Train: tensor(1.0486)\n",
            "80.955\n",
            "Loss Validation: tensor(1.0786)\n",
            "81.09\n",
            "Loss Train: tensor(1.1244)\n",
            "80.75166666666667\n",
            "Loss Validation: tensor(0.9950)\n",
            "81.42\n",
            "Loss Train: tensor(1.0447)\n",
            "81.00666666666666\n",
            "Loss Validation: tensor(1.0747)\n",
            "81.19\n",
            "Loss Train: tensor(1.1202)\n",
            "80.79666666666667\n",
            "Loss Validation: tensor(0.9914)\n",
            "81.5\n",
            "Loss Train: tensor(1.0409)\n",
            "81.035\n",
            "Loss Validation: tensor(1.0708)\n",
            "81.22\n",
            "Loss Train: tensor(1.1161)\n",
            "80.83833333333334\n",
            "Loss Validation: tensor(0.9879)\n",
            "81.53\n",
            "Loss Train: tensor(1.0371)\n",
            "81.085\n",
            "Loss Validation: tensor(1.0670)\n",
            "81.22\n",
            "Loss Train: tensor(1.1121)\n",
            "80.9\n",
            "Loss Validation: tensor(0.9844)\n",
            "81.62\n",
            "Loss Train: tensor(1.0333)\n",
            "81.14333333333333\n",
            "Loss Validation: tensor(1.0632)\n",
            "81.31\n",
            "Loss Train: tensor(1.1081)\n",
            "80.95666666666666\n",
            "Loss Validation: tensor(0.9809)\n",
            "81.66\n",
            "Loss Train: tensor(1.0296)\n",
            "81.21166666666667\n",
            "Loss Validation: tensor(1.0595)\n",
            "81.35\n",
            "Loss Train: tensor(1.1041)\n",
            "81.02166666666666\n",
            "Loss Validation: tensor(0.9775)\n",
            "81.74\n",
            "Loss Train: tensor(1.0259)\n",
            "81.26\n",
            "Loss Validation: tensor(1.0558)\n",
            "81.4\n",
            "Loss Train: tensor(1.1002)\n",
            "81.075\n",
            "Loss Validation: tensor(0.9741)\n",
            "81.88\n",
            "Loss Train: tensor(1.0223)\n",
            "81.31666666666666\n",
            "Loss Validation: tensor(1.0521)\n",
            "81.47\n",
            "Loss Train: tensor(1.0964)\n",
            "81.125\n",
            "Loss Validation: tensor(0.9707)\n",
            "81.95\n",
            "Loss Train: tensor(1.0187)\n",
            "81.40333333333334\n",
            "Loss Validation: tensor(1.0485)\n",
            "81.54\n",
            "Loss Train: tensor(1.0925)\n",
            "81.17166666666667\n",
            "Loss Validation: tensor(0.9674)\n",
            "82.0\n",
            "Loss Train: tensor(1.0151)\n",
            "81.46166666666667\n",
            "Loss Validation: tensor(1.0449)\n",
            "81.54\n",
            "Loss Train: tensor(1.0888)\n",
            "81.22166666666666\n",
            "Loss Validation: tensor(0.9641)\n",
            "82.02\n",
            "Loss Train: tensor(1.0116)\n",
            "81.50833333333334\n",
            "Loss Validation: tensor(1.0413)\n",
            "81.6\n",
            "Loss Train: tensor(1.0850)\n",
            "81.28\n",
            "Loss Validation: tensor(0.9608)\n",
            "82.08\n",
            "Loss Train: tensor(1.0081)\n",
            "81.57\n",
            "Loss Validation: tensor(1.0378)\n",
            "81.67\n",
            "Loss Train: tensor(1.0813)\n",
            "81.33666666666667\n",
            "Loss Validation: tensor(0.9576)\n",
            "82.06\n",
            "Loss Train: tensor(1.0046)\n",
            "81.61\n",
            "Loss Validation: tensor(1.0343)\n",
            "81.71\n",
            "Loss Train: tensor(1.0776)\n",
            "81.37333333333333\n",
            "Loss Validation: tensor(0.9544)\n",
            "82.13\n",
            "Loss Train: tensor(1.0012)\n",
            "81.65833333333333\n",
            "Loss Validation: tensor(1.0309)\n",
            "81.76\n",
            "Loss Train: tensor(1.0740)\n",
            "81.45\n",
            "Loss Validation: tensor(0.9512)\n",
            "82.14\n",
            "Loss Train: tensor(0.9978)\n",
            "81.70166666666667\n",
            "Loss Validation: tensor(1.0275)\n",
            "81.81\n",
            "Loss Train: tensor(1.0704)\n",
            "81.495\n",
            "Loss Validation: tensor(0.9481)\n",
            "82.24\n",
            "Loss Train: tensor(0.9944)\n",
            "81.73333333333333\n",
            "Loss Validation: tensor(1.0241)\n",
            "81.8\n",
            "Loss Train: tensor(1.0668)\n",
            "81.54333333333334\n",
            "Loss Validation: tensor(0.9450)\n",
            "82.29\n",
            "Loss Train: tensor(0.9911)\n",
            "81.77166666666666\n",
            "Loss Validation: tensor(1.0207)\n",
            "81.83\n",
            "Loss Train: tensor(1.0632)\n",
            "81.59\n",
            "Loss Validation: tensor(0.9419)\n",
            "82.33\n",
            "Loss Train: tensor(0.9878)\n",
            "81.84\n",
            "Loss Validation: tensor(1.0174)\n",
            "81.92\n",
            "Loss Train: tensor(1.0598)\n",
            "81.645\n",
            "Loss Validation: tensor(0.9389)\n",
            "82.37\n",
            "Loss Train: tensor(0.9845)\n",
            "81.895\n",
            "Loss Validation: tensor(1.0140)\n",
            "81.94\n",
            "Loss Train: tensor(1.0563)\n",
            "81.7\n",
            "Loss Validation: tensor(0.9359)\n",
            "82.41\n",
            "Loss Train: tensor(0.9813)\n",
            "81.93333333333334\n",
            "Loss Validation: tensor(1.0108)\n",
            "81.98\n",
            "Loss Train: tensor(1.0528)\n",
            "81.74\n",
            "Loss Validation: tensor(0.9329)\n",
            "82.45\n",
            "Loss Train: tensor(0.9781)\n",
            "81.985\n",
            "Loss Validation: tensor(1.0075)\n",
            "82.02\n",
            "Loss Train: tensor(1.0494)\n",
            "81.785\n",
            "Loss Validation: tensor(0.9299)\n",
            "82.48\n",
            "Loss Train: tensor(0.9749)\n",
            "82.02666666666667\n",
            "Loss Validation: tensor(1.0043)\n",
            "82.07\n",
            "Loss Train: tensor(1.0460)\n",
            "81.80333333333333\n",
            "Loss Validation: tensor(0.9269)\n",
            "82.5\n",
            "Loss Train: tensor(0.9717)\n",
            "82.075\n",
            "Loss Validation: tensor(1.0010)\n",
            "82.09\n",
            "Loss Train: tensor(1.0426)\n",
            "81.84166666666667\n",
            "Loss Validation: tensor(0.9240)\n",
            "82.56\n",
            "Loss Train: tensor(0.9686)\n",
            "82.12666666666667\n",
            "Loss Validation: tensor(0.9979)\n",
            "82.17\n",
            "Loss Train: tensor(1.0393)\n",
            "81.895\n",
            "Loss Validation: tensor(0.9211)\n",
            "82.56\n",
            "Loss Train: tensor(0.9655)\n",
            "82.15\n",
            "Loss Validation: tensor(0.9947)\n",
            "82.24\n",
            "Loss Train: tensor(1.0360)\n",
            "81.94166666666666\n",
            "Loss Validation: tensor(0.9182)\n",
            "82.6\n",
            "Loss Train: tensor(0.9624)\n",
            "82.20833333333333\n",
            "Loss Validation: tensor(0.9916)\n",
            "82.25\n",
            "Loss Train: tensor(1.0328)\n",
            "82.0\n",
            "Loss Validation: tensor(0.9154)\n",
            "82.66\n",
            "Loss Train: tensor(0.9594)\n",
            "82.27166666666666\n",
            "Loss Validation: tensor(0.9885)\n",
            "82.25\n",
            "Loss Train: tensor(1.0295)\n",
            "82.045\n",
            "Loss Validation: tensor(0.9126)\n",
            "82.67\n",
            "Loss Train: tensor(0.9564)\n",
            "82.31166666666667\n",
            "Loss Validation: tensor(0.9854)\n",
            "82.36\n",
            "Loss Train: tensor(1.0263)\n",
            "82.1\n",
            "Loss Validation: tensor(0.9097)\n",
            "82.7\n",
            "Loss Train: tensor(0.9534)\n",
            "82.37166666666667\n",
            "Loss Validation: tensor(0.9823)\n",
            "82.46\n",
            "Loss Train: tensor(1.0231)\n",
            "82.13666666666667\n",
            "Loss Validation: tensor(0.9070)\n",
            "82.75\n",
            "Loss Train: tensor(0.9504)\n",
            "82.435\n",
            "Loss Validation: tensor(0.9793)\n",
            "82.53\n",
            "Loss Train: tensor(1.0200)\n",
            "82.17833333333333\n",
            "Loss Validation: tensor(0.9042)\n",
            "82.79\n",
            "Loss Train: tensor(0.9475)\n",
            "82.48666666666666\n",
            "Loss Validation: tensor(0.9763)\n",
            "82.56\n",
            "Loss Train: tensor(1.0169)\n",
            "82.23666666666666\n",
            "Loss Validation: tensor(0.9015)\n",
            "82.83\n",
            "Loss Train: tensor(0.9446)\n",
            "82.54833333333333\n",
            "Loss Validation: tensor(0.9733)\n",
            "82.58\n",
            "Loss Train: tensor(1.0138)\n",
            "82.28333333333333\n",
            "Loss Validation: tensor(0.8987)\n",
            "82.85\n",
            "Loss Train: tensor(0.9417)\n",
            "82.585\n",
            "Loss Validation: tensor(0.9703)\n",
            "82.6\n",
            "Loss Train: tensor(1.0107)\n",
            "82.33\n",
            "Loss Validation: tensor(0.8961)\n",
            "82.9\n",
            "Loss Train: tensor(0.9389)\n",
            "82.63833333333334\n",
            "Loss Validation: tensor(0.9674)\n",
            "82.66\n",
            "Loss Train: tensor(1.0077)\n",
            "82.38\n",
            "Loss Validation: tensor(0.8934)\n",
            "82.92\n",
            "Loss Train: tensor(0.9360)\n",
            "82.69166666666666\n",
            "Loss Validation: tensor(0.9645)\n",
            "82.68\n",
            "Loss Train: tensor(1.0047)\n",
            "82.41666666666667\n",
            "Loss Validation: tensor(0.8907)\n",
            "82.98\n",
            "Loss Train: tensor(0.9332)\n",
            "82.72666666666667\n",
            "Loss Validation: tensor(0.9616)\n",
            "82.71\n",
            "Loss Train: tensor(1.0017)\n",
            "82.45666666666666\n",
            "Loss Validation: tensor(0.8881)\n",
            "83.03\n",
            "Loss Train: tensor(0.9305)\n",
            "82.78166666666667\n",
            "Loss Validation: tensor(0.9588)\n",
            "82.76\n",
            "Loss Train: tensor(0.9988)\n",
            "82.50166666666667\n",
            "Loss Validation: tensor(0.8855)\n",
            "83.03\n",
            "Loss Train: tensor(0.9277)\n",
            "82.8\n",
            "Loss Validation: tensor(0.9559)\n",
            "82.8\n",
            "Loss Train: tensor(0.9958)\n",
            "82.55666666666667\n",
            "Loss Validation: tensor(0.8829)\n",
            "83.07\n",
            "Loss Train: tensor(0.9250)\n",
            "82.82666666666667\n",
            "Loss Validation: tensor(0.9531)\n",
            "82.86\n",
            "Loss Train: tensor(0.9930)\n",
            "82.58666666666667\n",
            "Loss Validation: tensor(0.8804)\n",
            "83.13\n",
            "Loss Train: tensor(0.9223)\n",
            "82.86166666666666\n",
            "Loss Validation: tensor(0.9503)\n",
            "82.85\n",
            "Loss Train: tensor(0.9901)\n",
            "82.62333333333333\n",
            "Loss Validation: tensor(0.8778)\n",
            "83.16\n",
            "Loss Train: tensor(0.9196)\n",
            "82.915\n",
            "Loss Validation: tensor(0.9476)\n",
            "82.87\n",
            "Loss Train: tensor(0.9872)\n",
            "82.655\n",
            "Loss Validation: tensor(0.8753)\n",
            "83.2\n",
            "Loss Train: tensor(0.9170)\n",
            "82.95166666666667\n",
            "Loss Validation: tensor(0.9449)\n",
            "82.92\n",
            "Loss Train: tensor(0.9844)\n",
            "82.66166666666666\n",
            "Loss Validation: tensor(0.8728)\n",
            "83.23\n",
            "Loss Train: tensor(0.9143)\n",
            "82.99333333333334\n",
            "Loss Validation: tensor(0.9421)\n",
            "82.98\n",
            "Loss Train: tensor(0.9816)\n",
            "82.71333333333334\n",
            "Loss Validation: tensor(0.8703)\n",
            "83.28\n",
            "Loss Train: tensor(0.9117)\n",
            "83.03\n",
            "Loss Validation: tensor(0.9394)\n",
            "82.99\n",
            "Loss Train: tensor(0.9788)\n",
            "82.74\n",
            "Loss Validation: tensor(0.8678)\n",
            "83.29\n",
            "Loss Train: tensor(0.9091)\n",
            "83.07166666666667\n",
            "Loss Validation: tensor(0.9368)\n",
            "83.01\n",
            "Loss Train: tensor(0.9761)\n",
            "82.785\n",
            "Loss Validation: tensor(0.8654)\n",
            "83.31\n",
            "Loss Train: tensor(0.9066)\n",
            "83.105\n",
            "Loss Validation: tensor(0.9341)\n",
            "83.02\n",
            "Loss Train: tensor(0.9734)\n",
            "82.82333333333334\n",
            "Loss Validation: tensor(0.8630)\n",
            "83.32\n",
            "Loss Train: tensor(0.9040)\n",
            "83.14833333333333\n",
            "Loss Validation: tensor(0.9315)\n",
            "83.07\n",
            "Loss Train: tensor(0.9707)\n",
            "82.84833333333333\n",
            "Loss Validation: tensor(0.8606)\n",
            "83.39\n",
            "Loss Train: tensor(0.9015)\n",
            "83.17333333333333\n",
            "Loss Validation: tensor(0.9289)\n",
            "83.12\n",
            "Loss Train: tensor(0.9680)\n",
            "82.89166666666667\n",
            "Loss Validation: tensor(0.8582)\n",
            "83.4\n",
            "Loss Train: tensor(0.8990)\n",
            "83.205\n",
            "Loss Validation: tensor(0.9263)\n",
            "83.16\n",
            "Loss Train: tensor(0.9653)\n",
            "82.91666666666667\n",
            "Loss Validation: tensor(0.8558)\n",
            "83.45\n",
            "Loss Train: tensor(0.8965)\n",
            "83.25\n",
            "Loss Validation: tensor(0.9237)\n",
            "83.19\n",
            "Loss Train: tensor(0.9627)\n",
            "82.945\n",
            "Loss Validation: tensor(0.8535)\n",
            "83.44\n",
            "Loss Train: tensor(0.8941)\n",
            "83.27\n",
            "Loss Validation: tensor(0.9212)\n",
            "83.24\n",
            "Loss Train: tensor(0.9601)\n",
            "82.98333333333333\n",
            "Loss Validation: tensor(0.8512)\n",
            "83.49\n",
            "Loss Train: tensor(0.8916)\n",
            "83.29333333333334\n",
            "Loss Validation: tensor(0.9187)\n",
            "83.28\n",
            "Loss Train: tensor(0.9575)\n",
            "83.01833333333333\n",
            "Loss Validation: tensor(0.8489)\n",
            "83.53\n",
            "Loss Train: tensor(0.8892)\n",
            "83.32833333333333\n",
            "Loss Validation: tensor(0.9162)\n",
            "83.32\n",
            "Loss Train: tensor(0.9549)\n",
            "83.035\n",
            "Loss Validation: tensor(0.8466)\n",
            "83.59\n",
            "Loss Train: tensor(0.8868)\n",
            "83.36166666666666\n",
            "Loss Validation: tensor(0.9138)\n",
            "83.37\n",
            "Loss Train: tensor(0.9524)\n",
            "83.06333333333333\n",
            "Loss Validation: tensor(0.8443)\n",
            "83.59\n",
            "Loss Train: tensor(0.8844)\n",
            "83.39833333333333\n",
            "Loss Validation: tensor(0.9113)\n",
            "83.37\n",
            "Loss Train: tensor(0.9498)\n",
            "83.08333333333333\n",
            "Loss Validation: tensor(0.8421)\n",
            "83.64\n",
            "Loss Train: tensor(0.8820)\n",
            "83.43\n",
            "Loss Validation: tensor(0.9089)\n",
            "83.39\n",
            "Loss Train: tensor(0.9473)\n",
            "83.09\n",
            "Loss Validation: tensor(0.8398)\n",
            "83.65\n",
            "Loss Train: tensor(0.8797)\n",
            "83.44333333333333\n",
            "Loss Validation: tensor(0.9065)\n",
            "83.45\n",
            "Loss Train: tensor(0.9448)\n",
            "83.115\n",
            "Loss Validation: tensor(0.8376)\n",
            "83.7\n",
            "Loss Train: tensor(0.8774)\n",
            "83.45166666666667\n",
            "Loss Validation: tensor(0.9041)\n",
            "83.48\n",
            "Loss Train: tensor(0.9424)\n",
            "83.13166666666666\n",
            "Loss Validation: tensor(0.8354)\n",
            "83.71\n",
            "Loss Train: tensor(0.8750)\n",
            "83.46166666666667\n",
            "Loss Validation: tensor(0.9018)\n",
            "83.52\n",
            "Loss Train: tensor(0.9399)\n",
            "83.165\n",
            "Loss Validation: tensor(0.8333)\n",
            "83.71\n",
            "Loss Train: tensor(0.8727)\n",
            "83.50166666666667\n",
            "Loss Validation: tensor(0.8994)\n",
            "83.54\n",
            "Loss Train: tensor(0.9375)\n",
            "83.18166666666667\n",
            "Loss Validation: tensor(0.8311)\n",
            "83.72\n",
            "Loss Train: tensor(0.8705)\n",
            "83.54166666666667\n",
            "Loss Validation: tensor(0.8971)\n",
            "83.57\n",
            "Loss Train: tensor(0.9351)\n",
            "83.215\n",
            "Loss Validation: tensor(0.8290)\n",
            "83.7\n",
            "Loss Train: tensor(0.8682)\n",
            "83.56833333333333\n",
            "Loss Validation: tensor(0.8948)\n",
            "83.6\n",
            "Loss Train: tensor(0.9327)\n",
            "83.24833333333333\n",
            "Loss Validation: tensor(0.8269)\n",
            "83.72\n",
            "Loss Train: tensor(0.8660)\n",
            "83.57666666666667\n",
            "Loss Validation: tensor(0.8925)\n",
            "83.65\n",
            "Loss Train: tensor(0.9303)\n",
            "83.28333333333333\n",
            "Loss Validation: tensor(0.8248)\n",
            "83.74\n",
            "Loss Train: tensor(0.8638)\n",
            "83.605\n",
            "Loss Validation: tensor(0.8903)\n",
            "83.71\n",
            "Loss Train: tensor(0.9280)\n",
            "83.33\n",
            "Loss Validation: tensor(0.8227)\n",
            "83.76\n",
            "Loss Train: tensor(0.8616)\n",
            "83.64833333333333\n",
            "Loss Validation: tensor(0.8880)\n",
            "83.72\n",
            "Loss Train: tensor(0.9256)\n",
            "83.35333333333334\n",
            "Loss Validation: tensor(0.8206)\n",
            "83.82\n",
            "Loss Train: tensor(0.8594)\n",
            "83.68166666666667\n",
            "Loss Validation: tensor(0.8858)\n",
            "83.72\n",
            "Loss Train: tensor(0.9233)\n",
            "83.365\n",
            "Loss Validation: tensor(0.8186)\n",
            "83.85\n",
            "Loss Train: tensor(0.8572)\n",
            "83.70833333333333\n",
            "Loss Validation: tensor(0.8836)\n",
            "83.74\n",
            "Loss Train: tensor(0.9210)\n",
            "83.38166666666666\n",
            "Loss Validation: tensor(0.8165)\n",
            "83.89\n",
            "Loss Train: tensor(0.8550)\n",
            "83.74166666666666\n",
            "Loss Validation: tensor(0.8814)\n",
            "83.77\n",
            "Loss Train: tensor(0.9187)\n",
            "83.415\n",
            "Loss Validation: tensor(0.8145)\n",
            "83.89\n",
            "Loss Train: tensor(0.8529)\n",
            "83.765\n",
            "Loss Validation: tensor(0.8792)\n",
            "83.78\n",
            "Loss Train: tensor(0.9164)\n",
            "83.455\n",
            "Loss Validation: tensor(0.8125)\n",
            "83.95\n",
            "Loss Train: tensor(0.8508)\n",
            "83.78666666666666\n",
            "Loss Validation: tensor(0.8771)\n",
            "83.85\n",
            "Loss Train: tensor(0.9142)\n",
            "83.46833333333333\n",
            "Loss Validation: tensor(0.8105)\n",
            "83.99\n",
            "Loss Train: tensor(0.8487)\n",
            "83.805\n",
            "Loss Validation: tensor(0.8750)\n",
            "83.92\n",
            "Loss Train: tensor(0.9120)\n",
            "83.49833333333333\n",
            "Loss Validation: tensor(0.8086)\n",
            "84.06\n",
            "Loss Train: tensor(0.8466)\n",
            "83.835\n",
            "Loss Validation: tensor(0.8729)\n",
            "83.94\n",
            "Loss Train: tensor(0.9098)\n",
            "83.51333333333334\n",
            "Loss Validation: tensor(0.8066)\n",
            "84.06\n",
            "Loss Train: tensor(0.8445)\n",
            "83.85833333333333\n",
            "Loss Validation: tensor(0.8708)\n",
            "84.01\n",
            "Loss Train: tensor(0.9076)\n",
            "83.54\n",
            "Loss Validation: tensor(0.8047)\n",
            "84.12\n",
            "Loss Train: tensor(0.8425)\n",
            "83.87\n",
            "Loss Validation: tensor(0.8687)\n",
            "84.04\n",
            "Loss Train: tensor(0.9054)\n",
            "83.55666666666667\n",
            "Loss Validation: tensor(0.8028)\n",
            "84.19\n",
            "Loss Train: tensor(0.8405)\n",
            "83.895\n",
            "Loss Validation: tensor(0.8667)\n",
            "84.08\n",
            "Loss Train: tensor(0.9033)\n",
            "83.57833333333333\n",
            "Loss Validation: tensor(0.8009)\n",
            "84.18\n",
            "Loss Train: tensor(0.8384)\n",
            "83.92\n",
            "Loss Validation: tensor(0.8646)\n",
            "84.12\n",
            "Loss Train: tensor(0.9011)\n",
            "83.60833333333333\n",
            "Loss Validation: tensor(0.7990)\n",
            "84.22\n",
            "Loss Train: tensor(0.8364)\n",
            "83.95333333333333\n",
            "Loss Validation: tensor(0.8626)\n",
            "84.17\n",
            "Loss Train: tensor(0.8990)\n",
            "83.63333333333334\n",
            "Loss Validation: tensor(0.7972)\n",
            "84.25\n",
            "Loss Train: tensor(0.8345)\n",
            "83.99\n",
            "Loss Validation: tensor(0.8606)\n",
            "84.19\n",
            "Loss Train: tensor(0.8969)\n",
            "83.66\n",
            "Loss Validation: tensor(0.7953)\n",
            "84.28\n",
            "Loss Train: tensor(0.8325)\n",
            "84.01833333333333\n",
            "Loss Validation: tensor(0.8587)\n",
            "84.22\n",
            "Loss Train: tensor(0.8948)\n",
            "83.69166666666666\n",
            "Loss Validation: tensor(0.7935)\n",
            "84.27\n",
            "Loss Train: tensor(0.8305)\n",
            "84.04833333333333\n",
            "Loss Validation: tensor(0.8567)\n",
            "84.27\n",
            "Loss Train: tensor(0.8927)\n",
            "83.72166666666666\n",
            "Loss Validation: tensor(0.7917)\n",
            "84.29\n",
            "Loss Train: tensor(0.8286)\n",
            "84.06\n",
            "Loss Validation: tensor(0.8548)\n",
            "84.3\n",
            "Loss Train: tensor(0.8907)\n",
            "83.76166666666667\n",
            "Loss Validation: tensor(0.7899)\n",
            "84.36\n",
            "Loss Train: tensor(0.8267)\n",
            "84.10166666666667\n",
            "Loss Validation: tensor(0.8528)\n",
            "84.36\n",
            "Loss Train: tensor(0.8886)\n",
            "83.77666666666667\n",
            "Loss Validation: tensor(0.7881)\n",
            "84.4\n",
            "Loss Train: tensor(0.8248)\n",
            "84.13666666666667\n",
            "Loss Validation: tensor(0.8509)\n",
            "84.42\n",
            "Loss Train: tensor(0.8866)\n",
            "83.805\n",
            "Loss Validation: tensor(0.7863)\n",
            "84.43\n",
            "Loss Train: tensor(0.8229)\n",
            "84.17\n",
            "Loss Validation: tensor(0.8490)\n",
            "84.46\n",
            "Loss Train: tensor(0.8846)\n",
            "83.83333333333333\n",
            "Loss Validation: tensor(0.7845)\n",
            "84.44\n",
            "Loss Train: tensor(0.8210)\n",
            "84.19\n",
            "Loss Validation: tensor(0.8471)\n",
            "84.51\n",
            "Loss Train: tensor(0.8826)\n",
            "83.87166666666667\n",
            "Loss Validation: tensor(0.7827)\n",
            "84.44\n",
            "Loss Train: tensor(0.8191)\n",
            "84.22666666666667\n",
            "Loss Validation: tensor(0.8452)\n",
            "84.54\n",
            "Loss Train: tensor(0.8806)\n",
            "83.90333333333334\n",
            "Loss Validation: tensor(0.7810)\n",
            "84.45\n",
            "Loss Train: tensor(0.8173)\n",
            "84.255\n",
            "Loss Validation: tensor(0.8433)\n",
            "84.52\n",
            "Loss Train: tensor(0.8787)\n",
            "83.92\n",
            "Loss Validation: tensor(0.7793)\n",
            "84.47\n",
            "Loss Train: tensor(0.8154)\n",
            "84.29666666666667\n",
            "Loss Validation: tensor(0.8415)\n",
            "84.51\n",
            "Loss Train: tensor(0.8767)\n",
            "83.95333333333333\n",
            "Loss Validation: tensor(0.7775)\n",
            "84.49\n",
            "Loss Train: tensor(0.8136)\n",
            "84.30666666666667\n",
            "Loss Validation: tensor(0.8396)\n",
            "84.53\n",
            "Loss Train: tensor(0.8748)\n",
            "83.97166666666666\n",
            "Loss Validation: tensor(0.7758)\n",
            "84.48\n",
            "Loss Train: tensor(0.8118)\n",
            "84.36333333333333\n",
            "Loss Validation: tensor(0.8378)\n",
            "84.54\n",
            "Loss Train: tensor(0.8728)\n",
            "84.01\n",
            "Loss Validation: tensor(0.7741)\n",
            "84.51\n",
            "Loss Train: tensor(0.8099)\n",
            "84.39\n",
            "Loss Validation: tensor(0.8360)\n",
            "84.55\n",
            "Loss Train: tensor(0.8709)\n",
            "84.04166666666667\n",
            "Loss Validation: tensor(0.7724)\n",
            "84.52\n",
            "Loss Train: tensor(0.8082)\n",
            "84.40833333333333\n",
            "Loss Validation: tensor(0.8342)\n",
            "84.57\n",
            "Loss Train: tensor(0.8690)\n",
            "84.07\n",
            "Loss Validation: tensor(0.7708)\n",
            "84.54\n",
            "Loss Train: tensor(0.8064)\n",
            "84.41666666666667\n",
            "Loss Validation: tensor(0.8324)\n",
            "84.56\n",
            "Loss Train: tensor(0.8672)\n",
            "84.09833333333333\n",
            "Loss Validation: tensor(0.7691)\n",
            "84.62\n",
            "Loss Train: tensor(0.8046)\n",
            "84.44\n",
            "Loss Validation: tensor(0.8306)\n",
            "84.61\n",
            "Loss Train: tensor(0.8653)\n",
            "84.11166666666666\n",
            "Loss Validation: tensor(0.7675)\n",
            "84.66\n",
            "Loss Train: tensor(0.8029)\n",
            "84.46666666666667\n",
            "Loss Validation: tensor(0.8289)\n",
            "84.63\n",
            "Loss Train: tensor(0.8634)\n",
            "84.13166666666666\n",
            "Loss Validation: tensor(0.7658)\n",
            "84.69\n",
            "Loss Train: tensor(0.8011)\n",
            "84.495\n",
            "Loss Validation: tensor(0.8271)\n",
            "84.64\n",
            "Loss Train: tensor(0.8616)\n",
            "84.15333333333334\n",
            "Loss Validation: tensor(0.7642)\n",
            "84.72\n",
            "Loss Train: tensor(0.7994)\n",
            "84.51333333333334\n",
            "Loss Validation: tensor(0.8254)\n",
            "84.65\n",
            "Loss Train: tensor(0.8598)\n",
            "84.17333333333333\n",
            "Loss Validation: tensor(0.7626)\n",
            "84.74\n",
            "Loss Train: tensor(0.7977)\n",
            "84.53833333333333\n",
            "Loss Validation: tensor(0.8236)\n",
            "84.65\n",
            "Loss Train: tensor(0.8579)\n",
            "84.18166666666667\n",
            "Loss Validation: tensor(0.7610)\n",
            "84.75\n",
            "Loss Train: tensor(0.7960)\n",
            "84.56\n",
            "Loss Validation: tensor(0.8219)\n",
            "84.67\n",
            "Loss Train: tensor(0.8561)\n",
            "84.20833333333333\n",
            "Loss Validation: tensor(0.7594)\n",
            "84.74\n",
            "Loss Train: tensor(0.7943)\n",
            "84.59\n",
            "Loss Validation: tensor(0.8202)\n",
            "84.7\n",
            "Loss Train: tensor(0.8543)\n",
            "84.21833333333333\n",
            "Loss Validation: tensor(0.7578)\n",
            "84.76\n",
            "Loss Train: tensor(0.7926)\n",
            "84.60333333333334\n",
            "Loss Validation: tensor(0.8185)\n",
            "84.7\n",
            "Loss Train: tensor(0.8526)\n",
            "84.23333333333333\n",
            "Loss Validation: tensor(0.7563)\n",
            "84.78\n",
            "Loss Train: tensor(0.7910)\n",
            "84.61666666666666\n",
            "Loss Validation: tensor(0.8169)\n",
            "84.73\n",
            "Loss Train: tensor(0.8508)\n",
            "84.26333333333334\n",
            "Loss Validation: tensor(0.7547)\n",
            "84.79\n",
            "Loss Train: tensor(0.7893)\n",
            "84.635\n",
            "Loss Validation: tensor(0.8152)\n",
            "84.76\n",
            "Loss Train: tensor(0.8491)\n",
            "84.28333333333333\n",
            "Loss Validation: tensor(0.7532)\n",
            "84.79\n",
            "Loss Train: tensor(0.7877)\n",
            "84.655\n",
            "Loss Validation: tensor(0.8136)\n",
            "84.76\n",
            "Loss Train: tensor(0.8473)\n",
            "84.30833333333334\n",
            "Loss Validation: tensor(0.7516)\n",
            "84.78\n",
            "Loss Train: tensor(0.7860)\n",
            "84.675\n",
            "Loss Validation: tensor(0.8119)\n",
            "84.78\n",
            "Loss Train: tensor(0.8456)\n",
            "84.325\n",
            "Loss Validation: tensor(0.7501)\n",
            "84.81\n",
            "Loss Train: tensor(0.7844)\n",
            "84.69333333333333\n",
            "Loss Validation: tensor(0.8103)\n",
            "84.8\n",
            "Loss Train: tensor(0.8439)\n",
            "84.35833333333333\n",
            "Loss Validation: tensor(0.7486)\n",
            "84.85\n",
            "Loss Train: tensor(0.7828)\n",
            "84.71166666666667\n",
            "Loss Validation: tensor(0.8087)\n",
            "84.81\n",
            "Loss Train: tensor(0.8422)\n",
            "84.37666666666667\n",
            "Loss Validation: tensor(0.7471)\n",
            "84.84\n",
            "Loss Train: tensor(0.7812)\n",
            "84.735\n",
            "Loss Validation: tensor(0.8071)\n",
            "84.8\n",
            "Loss Train: tensor(0.8406)\n",
            "84.39\n",
            "Loss Validation: tensor(0.7456)\n",
            "84.85\n",
            "Loss Train: tensor(0.7797)\n",
            "84.75833333333334\n",
            "Loss Validation: tensor(0.8055)\n",
            "84.82\n",
            "Loss Train: tensor(0.8389)\n",
            "84.41\n",
            "Loss Validation: tensor(0.7441)\n",
            "84.88\n",
            "Loss Train: tensor(0.7781)\n",
            "84.78\n",
            "Loss Validation: tensor(0.8039)\n",
            "84.85\n",
            "Loss Train: tensor(0.8372)\n",
            "84.44\n",
            "Loss Validation: tensor(0.7426)\n",
            "84.88\n",
            "Loss Train: tensor(0.7766)\n",
            "84.8\n",
            "Loss Validation: tensor(0.8023)\n",
            "84.86\n",
            "Loss Train: tensor(0.8356)\n",
            "84.46666666666667\n",
            "Loss Validation: tensor(0.7412)\n",
            "84.92\n",
            "Loss Train: tensor(0.7750)\n",
            "84.83166666666666\n",
            "Loss Validation: tensor(0.8008)\n",
            "84.88\n",
            "Loss Train: tensor(0.8340)\n",
            "84.47833333333334\n",
            "Loss Validation: tensor(0.7397)\n",
            "84.91\n",
            "Loss Train: tensor(0.7735)\n",
            "84.86333333333333\n",
            "Loss Validation: tensor(0.7993)\n",
            "84.89\n",
            "Loss Train: tensor(0.8324)\n",
            "84.50166666666667\n",
            "Loss Validation: tensor(0.7383)\n",
            "84.95\n",
            "Loss Train: tensor(0.7720)\n",
            "84.875\n",
            "Loss Validation: tensor(0.7978)\n",
            "84.91\n",
            "Loss Train: tensor(0.8308)\n",
            "84.52833333333334\n",
            "Loss Validation: tensor(0.7369)\n",
            "84.96\n",
            "Loss Train: tensor(0.7705)\n",
            "84.89166666666667\n",
            "Loss Validation: tensor(0.7962)\n",
            "84.91\n",
            "Loss Train: tensor(0.8292)\n",
            "84.54333333333334\n",
            "Loss Validation: tensor(0.7354)\n",
            "84.98\n",
            "Loss Train: tensor(0.7690)\n",
            "84.89666666666666\n",
            "Loss Validation: tensor(0.7947)\n",
            "84.96\n",
            "Loss Train: tensor(0.8276)\n",
            "84.55666666666667\n",
            "Loss Validation: tensor(0.7340)\n",
            "84.99\n",
            "Loss Train: tensor(0.7675)\n",
            "84.92166666666667\n",
            "Loss Validation: tensor(0.7932)\n",
            "84.96\n",
            "Loss Train: tensor(0.8261)\n",
            "84.57333333333334\n",
            "Loss Validation: tensor(0.7326)\n",
            "85.02\n",
            "Loss Train: tensor(0.7660)\n",
            "84.945\n",
            "Loss Validation: tensor(0.7918)\n",
            "84.99\n",
            "Loss Train: tensor(0.8245)\n",
            "84.585\n",
            "Loss Validation: tensor(0.7313)\n",
            "85.04\n",
            "Loss Train: tensor(0.7645)\n",
            "84.96166666666667\n",
            "Loss Validation: tensor(0.7903)\n",
            "85.01\n",
            "Loss Train: tensor(0.8230)\n",
            "84.60666666666667\n",
            "Loss Validation: tensor(0.7299)\n",
            "85.05\n",
            "Loss Train: tensor(0.7631)\n",
            "84.98333333333333\n",
            "Loss Validation: tensor(0.7888)\n",
            "85.02\n",
            "Loss Train: tensor(0.8214)\n",
            "84.62666666666667\n",
            "Loss Validation: tensor(0.7285)\n",
            "85.06\n",
            "Loss Train: tensor(0.7616)\n",
            "85.0\n",
            "Loss Validation: tensor(0.7874)\n",
            "85.04\n",
            "Loss Train: tensor(0.8199)\n",
            "84.645\n",
            "Loss Validation: tensor(0.7272)\n",
            "85.08\n",
            "Loss Train: tensor(0.7602)\n",
            "85.025\n",
            "Loss Validation: tensor(0.7860)\n",
            "85.06\n",
            "Loss Train: tensor(0.8184)\n",
            "84.66666666666667\n",
            "Loss Validation: tensor(0.7258)\n",
            "85.1\n",
            "Loss Train: tensor(0.7588)\n",
            "85.045\n",
            "Loss Validation: tensor(0.7846)\n",
            "85.05\n",
            "Loss Train: tensor(0.8169)\n",
            "84.69\n",
            "Loss Validation: tensor(0.7245)\n",
            "85.11\n",
            "Loss Train: tensor(0.7573)\n",
            "85.07833333333333\n",
            "Loss Validation: tensor(0.7832)\n",
            "85.07\n",
            "Loss Train: tensor(0.8154)\n",
            "84.69666666666667\n",
            "Loss Validation: tensor(0.7232)\n",
            "85.17\n",
            "Loss Train: tensor(0.7559)\n",
            "85.10333333333334\n",
            "Loss Validation: tensor(0.7817)\n",
            "85.08\n",
            "Loss Train: tensor(0.8140)\n",
            "84.715\n",
            "Loss Validation: tensor(0.7218)\n",
            "85.17\n",
            "Loss Train: tensor(0.7545)\n",
            "85.11833333333334\n",
            "Loss Validation: tensor(0.7804)\n",
            "85.11\n",
            "Loss Train: tensor(0.8125)\n",
            "84.73166666666667\n",
            "Loss Validation: tensor(0.7205)\n",
            "85.17\n",
            "Loss Train: tensor(0.7532)\n",
            "85.15166666666667\n",
            "Loss Validation: tensor(0.7790)\n",
            "85.14\n",
            "Loss Train: tensor(0.8111)\n",
            "84.75333333333333\n",
            "Loss Validation: tensor(0.7192)\n",
            "85.2\n",
            "Loss Train: tensor(0.7518)\n",
            "85.17333333333333\n",
            "Loss Validation: tensor(0.7776)\n",
            "85.16\n",
            "Loss Train: tensor(0.8096)\n",
            "84.78333333333333\n",
            "Loss Validation: tensor(0.7179)\n",
            "85.2\n",
            "Loss Train: tensor(0.7504)\n",
            "85.19333333333333\n",
            "Loss Validation: tensor(0.7762)\n",
            "85.2\n",
            "Loss Train: tensor(0.8082)\n",
            "84.80833333333334\n",
            "Loss Validation: tensor(0.7167)\n",
            "85.19\n",
            "Loss Train: tensor(0.7490)\n",
            "85.21833333333333\n",
            "Loss Validation: tensor(0.7749)\n",
            "85.21\n"
          ]
        }
      ]
    }
  ]
}
