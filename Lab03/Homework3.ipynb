{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import Tensor\n",
    "import numpy as np\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transform\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from random import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "\n",
    "#MNIST datasets\n",
    "mnist_trainset = datasets.MNIST(root='./data', train=True, download=True, transform=transform.ToTensor())\n",
    "mnist_testset = datasets.MNIST(root='./data', train=False, download=True, transform=transform.ToTensor())\n",
    "\n",
    "mnist_trainloader : DataLoader = DataLoader(mnist_trainset, batch_size=batch_size, shuffle=True)\n",
    "mnist_testloader : DataLoader = DataLoader(mnist_testset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 43.10, Accuracy: 93.53%\n"
     ]
    }
   ],
   "source": [
    "epochs = 30\n",
    "W_hidden = torch.randn(784, 100)\n",
    "b_hidden = torch.randn(100)\n",
    "mu = 0.3\n",
    "\n",
    "W_output = torch.randn(100, 10)\n",
    "b_output = torch.randn(10)\n",
    "\n",
    "def train():\n",
    "    global W_hidden\n",
    "    global b_hidden\n",
    "    global W_output\n",
    "    global b_output\n",
    "\n",
    "    #only for acc & loss\n",
    "    cross_entropy_loss = torch.nn.CrossEntropyLoss()\n",
    "    ok = 0\n",
    "    samples = 0\n",
    "    loss = 0\n",
    "\n",
    "    num_batches = len(mnist_testloader)//batch_size\n",
    "    dropout_threshold = 5 * num_batches // 100\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        for inputs, labels in mnist_trainloader:\n",
    "            \n",
    "            if randint(0, num_batches) < dropout_threshold:\n",
    "                continue\n",
    "\n",
    "            #forwardprop\n",
    "            x = inputs.view(batch_size, -1)\n",
    "            \n",
    "            Z_hidden = (x @ W_hidden) + b_hidden\n",
    "            Y_hidden = sigmoid(Z_hidden)\n",
    "\n",
    "            Z_output = (Y_hidden @ W_output) + b_output\n",
    "            Y_output = sigmoid(Z_output)\n",
    "\n",
    "            #calculate loss & acc during training\n",
    "            loss += cross_entropy_loss(Z_output, labels).item()\n",
    "            predictions = torch.argmax(Y_output, dim=1)\n",
    "\n",
    "            ok += (predictions == labels).sum().item()\n",
    "            samples += predictions.size(0)\n",
    "\n",
    "            encoded_label = torch.zeros(batch_size, 10)\n",
    "            for index, label in enumerate(labels):\n",
    "                encoded_label[index][label] = 1\n",
    "\n",
    "            #backprop batch\n",
    "\n",
    "            #derivs for output layer\n",
    "            output_error = Y_output - encoded_label\n",
    "            deltaWL_output : Tensor = (Y_hidden.t() @ output_error) / batch_size\n",
    "            deltabL_output : Tensor = torch.sum(output_error, dim=0, keepdim=True) / batch_size\n",
    "\n",
    "            #derivs for hidden layer\n",
    "            Error_hidden = (output_error @ W_output.t()) * (Y_hidden * (1 - Y_hidden)).float()\n",
    "            deltaWL_hidden = (x.t() @ Error_hidden) / batch_size\n",
    "            deltabL_hidden = torch.sum(Error_hidden, dim=0, keepdim=True) / batch_size\n",
    "\n",
    "            #update\n",
    "            W_hidden -= mu * deltaWL_hidden\n",
    "            b_hidden -= mu * deltabL_hidden.squeeze(0)\n",
    "            W_output -= mu * deltaWL_output\n",
    "            b_output -= mu * deltabL_output.squeeze(0)\n",
    "\n",
    "    loss /= len(mnist_testloader)\n",
    "    accuracy = ok / samples\n",
    "    print(f\"Loss: {loss:.2f}, Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(dataset_loader):\n",
    "    global W_hidden\n",
    "    global b_hidden\n",
    "    global W_output\n",
    "    global b_output\n",
    "\n",
    "    ok = 0\n",
    "    samples = 0\n",
    "    loss = 0\n",
    "    cross_entropy_loss = torch.nn.CrossEntropyLoss()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataset_loader:\n",
    "            x = inputs.view(batch_size, -1)\n",
    "\n",
    "            Z_hidden = (x @ W_hidden) + b_hidden\n",
    "            Y_hidden = sigmoid(Z_hidden)\n",
    "\n",
    "            Z_output = (Y_hidden @ W_output) + b_output\n",
    "            Y_output = sigmoid(Z_output)\n",
    "            # print(Y_output)\n",
    "\n",
    "            loss += cross_entropy_loss(Z_output, labels).item()\n",
    "            predictions = torch.argmax(Y_output, dim=1)\n",
    "\n",
    "            ok += (predictions == labels).sum().item()\n",
    "            samples += predictions.size(0)\n",
    "\n",
    "    loss /= len(dataset_loader)\n",
    "    accuracy = ok / samples\n",
    "    print(f\"Loss: {loss:.2f}, Accuracy: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.13, Accuracy: 96.55%\n"
     ]
    }
   ],
   "source": [
    "predict(mnist_trainloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.20, Accuracy: 95.28%\n"
     ]
    }
   ],
   "source": [
    "predict(mnist_testloader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
