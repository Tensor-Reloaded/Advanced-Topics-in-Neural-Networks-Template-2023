{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "import torch\n",
    "import random\n",
    "from functools import lru_cache\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import pandas as pd\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision.transforms import Compose, RandomHorizontalFlip, ToTensor, Normalize, RandomAdjustSharpness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_time(filename):\n",
    "    start_index = filename.index(\"global_monthly_\") + len(\"global_monthly_\")\n",
    "    end_index = filename.index(\"_mosaic\")\n",
    "    year = int(filename[start_index:start_index+4])\n",
    "    month = int(filename[start_index+5:end_index])\n",
    "    return datetime.datetime(year, month, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = Compose([\n",
    "    ToTensor(),\n",
    "    Normalize(0.0006, 0.0011),\n",
    "    RandomHorizontalFlip(p=0.5),\n",
    "    RandomAdjustSharpness(0.5)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# caches the dataset in memory\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, folder_path, transform=None):\n",
    "        self.folder_path = folder_path\n",
    "        self.transform = transform\n",
    "        self.samples = []\n",
    "        \n",
    "        for location in os.listdir(folder_path):\n",
    "            location_path = os.path.join(folder_path, location, 'images')\n",
    "\n",
    "            location_images = []\n",
    "            for filename in os.listdir(location_path):\n",
    "                image_path = os.path.join(location_path, filename)\n",
    "                image = Image.open(image_path)\n",
    "                location_images.append((image, get_time(filename)))\n",
    "            sorted_location_images = sorted(location_images, key=lambda x: x[1].year)\n",
    "                    \n",
    "            for i in range(len(sorted_location_images) - 1):\n",
    "                for j in range(i+1, len(sorted_location_images)):\n",
    "                    start_image, start_datetime = sorted_location_images[i]\n",
    "                    end_image, end_datetime = sorted_location_images[j]\n",
    "                    time_skip = (end_datetime.year - start_datetime.year) * 12 + (end_datetime.month - start_datetime.month)\n",
    "                    if self.transform:\n",
    "                        self.samples.append((self.transform(start_image), self.transform(end_image), time_skip))\n",
    "                    else:\n",
    "                        self.samples.append((start_image, end_image, time_skip))\n",
    "\n",
    "                    # Random rotation augmentation\n",
    "                    angle = random.uniform(-90, 90)\n",
    "                    if self.transform:\n",
    "                        self.samples.append((self.transform(start_image.rotate(angle)), self.transform(end_image.rotate(angle)), time_skip))\n",
    "                    else:\n",
    "                        self.samples.append((start_image.rotate(angle), end_image.rotate(angle), time_skip))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    @lru_cache(maxsize=None)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.samples[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ImageDataset(folder_path='../Homework Dataset/', transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 128, 128])\n"
     ]
    }
   ],
   "source": [
    "# check image shape\n",
    "print(dataset[0][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum pixel value: 22\n",
      "Maximum pixel value: 255\n"
     ]
    }
   ],
   "source": [
    "# check image pixels range (0-255)\n",
    "image = Image.open('../Homework Dataset/L15-0595E-1278N_2383_3079_13/images/global_monthly_2018_01_mosaic_L15-0595E-1278N_2383_3079_13.tif')\n",
    "\n",
    "array = np.array(image)\n",
    "\n",
    "print(f'Minimum pixel value: {array.min()}')\n",
    "print(f'Maximum pixel value: {array.max()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before scaling: (tensor(0.1489), tensor(0.2887))\n",
      "After scaling: (tensor(0.0006), tensor(0.0011))\n"
     ]
    }
   ],
   "source": [
    "for location in os.listdir('../Homework Dataset/'):\n",
    "    location_path = os.path.join('../Homework Dataset/', location, 'images')\n",
    "\n",
    "    location_images = []\n",
    "    for filename in os.listdir(location_path):\n",
    "        image_path = os.path.join(location_path, filename)\n",
    "        image = Image.open(image_path)\n",
    "        location_images.append(ToTensor()(image))\n",
    "\n",
    "print(f'Before scaling: {torch.std_mean(torch.stack(location_images).float())}')\n",
    "print(f'After scaling: {torch.std_mean(torch.stack(location_images).float() / 255)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset: train, validation, test\n",
    "train_size = int(0.7 * len(dataset))\n",
    "val_size = int(0.15 * len(dataset))\n",
    "test_size = len(dataset) - train_size - val_size\n",
    "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start: torch.Size([32, 3, 128, 128]), End: torch.Size([32, 3, 128, 128]), Time: tensor([10,  2,  6, 24,  7,  6, 20,  5, 15, 16, 15,  5,  3,  7,  3, 10,  5,  5,\n",
      "         6, 12,  6,  7,  1,  4, 11,  8, 14, 10,  4,  7,  1, 16])\n",
      "Start: torch.Size([32, 3, 128, 128]), End: torch.Size([32, 3, 128, 128]), Time: tensor([ 5, 22, 17,  6, 21, 16, 14, 15, 12,  3, 14, 16, 15, 19,  1, 19,  6, 14,\n",
      "         9,  7,  1,  7, 11,  2, 10,  4, 16,  1, 21,  1,  9,  3])\n",
      "Start: torch.Size([32, 3, 128, 128]), End: torch.Size([32, 3, 128, 128]), Time: tensor([ 6,  7,  9,  6,  8,  1, 15, 18,  8, 14,  8, 21,  7, 17,  6,  4,  3,  5,\n",
      "         2,  3, 11, 11,  3, 12, 16,  6, 13, 16,  2,  3,  5,  8])\n"
     ]
    }
   ],
   "source": [
    "for start, end, time in train_loader:\n",
    "    print(f'Start: {start.shape}, End: {end.shape}, Time: {time}')\n",
    "    break\n",
    "for start, end, time in val_loader:\n",
    "    print(f'Start: {start.shape}, End: {end.shape}, Time: {time}')\n",
    "    break\n",
    "for start, end, time in test_loader:\n",
    "    print(f'Start: {start.shape}, End: {end.shape}, Time: {time}')\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy is not a suitable metric for predicting the future state of an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pipeline:\n",
    "    def __init__(self, model, optimizer, criterion):\n",
    "        self.model = model\n",
    "        self.optimizer = optimizer\n",
    "        self.criterion = criterion\n",
    "\n",
    "    def train(self, train_loader):\n",
    "        self.model.train()\n",
    "        running_loss = 0.0\n",
    "\n",
    "        for inputs, labels, times in train_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            times = times.to(device)\n",
    "\n",
    "            self.optimizer.zero_grad()\n",
    "\n",
    "            outputs = self.model(inputs, times)\n",
    "            loss = self.criterion(outputs, labels)\n",
    "\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "        return epoch_loss\n",
    "    \n",
    "    def val(self, val_loader):\n",
    "        self.model.eval()\n",
    "        running_loss = 0.0\n",
    "\n",
    "        for inputs, labels, times in val_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            times = times.to(device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                outputs = self.model(inputs, times)\n",
    "                loss = self.criterion(outputs, labels)\n",
    "\n",
    "                running_loss += loss.item()\n",
    "        \n",
    "        epoch_loss = running_loss / len(val_loader.dataset)\n",
    "        return epoch_loss\n",
    "    \n",
    "    def test(self, test_loader):\n",
    "        self.model.eval()\n",
    "        running_loss = 0.0\n",
    "\n",
    "        for inputs, labels, times in test_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            times = times.to(device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                outputs = self.model(inputs, times)\n",
    "                loss = self.criterion(outputs, labels)\n",
    "\n",
    "                running_loss += loss.item()\n",
    "        \n",
    "        epoch_loss = running_loss / len(test_loader.dataset)\n",
    "        return epoch_loss\n",
    "\n",
    "    def run(self, epochs, train_loader, val_loader, test_loader):\n",
    "        for epoch in range(epochs):\n",
    "            train_loss = self.train(train_loader)\n",
    "            val_loss = self.val(val_loader)\n",
    "            print(f'Epoch {epoch + 1}/{epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}')\n",
    "            \n",
    "            report.add_scalar('Train loss', train_loss, epoch)\n",
    "            report.add_scalar('Test loss', val_loss, epoch)\n",
    "        \n",
    "        test_loss = self.test(test_loader)\n",
    "        print(f'Test Loss: {test_loss:.4f}')\n",
    "        report.add_scalar('Test loss', test_loss, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Call `tensorboard --logdir=.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Conv2d, Linear, MaxPool2d, Module, MSELoss\n",
    "from torch.nn.functional import relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(Module):\n",
    "    def __init__(self):\n",
    "        super(Network, self).__init__()\n",
    "        self.conv1 = Conv2d(3, 6, 5)\n",
    "        self.pool = MaxPool2d(2, 2)\n",
    "        self.conv2 = Conv2d(6, 16, 5)\n",
    "        self.fc1 = Linear(16 * 29 * 29 + 1, 120)\n",
    "        self.fc2 = Linear(120, 84)\n",
    "        self.fc3 = Linear(84, 128*128*3)\n",
    "\n",
    "    def forward(self, x, time):\n",
    "        x = self.pool(relu(self.conv1(x)))\n",
    "        x = self.pool(relu(self.conv2(x)))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        time = time.unsqueeze(1)\n",
    "        x = torch.cat((x, time), dim=1)\n",
    "        x = relu(self.fc1(x))\n",
    "        x = relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        x = x.view(x.size(0), 3, 128, 128)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Network(\n",
       "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=13457, out_features=120, bias=True)\n",
       "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
       "  (fc3): Linear(in_features=84, out_features=49152, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Network()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MSELoss()"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion = MSELoss()\n",
    "criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(model=model, optimizer=optimizer, criterion=criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Train Loss: 55512.1832, Val Loss: 45573.1878\n",
      "Epoch 2/10, Train Loss: 45690.1099, Val Loss: 45599.2873\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "pipeline.run(epochs=10, train_loader=train_loader, val_loader=val_loader, test_loader=test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ATNN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
