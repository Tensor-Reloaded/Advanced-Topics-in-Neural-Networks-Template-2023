{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DxxN2Tjf5NIZ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "class HomeworkDataset(Dataset):\n",
        "    def __init__(self, folder_path, transform=None):\n",
        "        self.folder_path = folder_path\n",
        "        self.transform = transform\n",
        "        self.image_pairs = self.load_image_pairs()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_pairs)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        start_img_path, end_img_path, time_skip = self.image_pairs[idx]\n",
        "\n",
        "        if 'start_image_cache' not in self.__dict__:\n",
        "            self.start_image_cache = {}\n",
        "            self.end_image_cache = {}\n",
        "\n",
        "        if idx in self.start_image_cache:\n",
        "            start_img = self.start_image_cache[idx]\n",
        "        else:\n",
        "            start_img = Image.open(start_img_path).convert('RGB')\n",
        "            self.start_image_cache[idx] = start_img\n",
        "\n",
        "        if idx in self.end_image_cache:\n",
        "            end_img = self.end_image_cache[idx]\n",
        "        else:\n",
        "            end_img = Image.open(end_img_path).convert('RGB')\n",
        "            self.end_image_cache[idx] = end_img\n",
        "\n",
        "        print(f\"Start image shape after reading (H, W, C): {np.array(start_img).shape}\")\n",
        "        print(f\"End image shape after reading (H, W, C): {np.array(end_img).shape}\")\n",
        "\n",
        "        if self.transform:\n",
        "            aug = transforms.RandomRotation(30)\n",
        "            start_img = aug(start_img)\n",
        "            end_img = aug(end_img)\n",
        "            start_img = self.transform(start_img)\n",
        "            end_img = self.transform(end_img)\n",
        "\n",
        "            print(f\"Transformed start image shape: {start_img.shape}\")\n",
        "            print(f\"Transformed end image shape: {end_img.shape}\")\n",
        "\n",
        "            # convert tensors back to PIL images for proper visualization\n",
        "            plt.subplot(1, 2, 1)\n",
        "            plt.imshow(transforms.ToPILImage()(start_img))\n",
        "            plt.title(\"Start Image\")\n",
        "            plt.subplot(1, 2, 2)\n",
        "            plt.imshow(transforms.ToPILImage()(end_img))\n",
        "            plt.title(\"End Image\")\n",
        "            plt.show()\n",
        "\n",
        "        print(f\"Loading image pair {idx+1}/{self.__len__()}: Time skip: {time_skip} months\")\n",
        "\n",
        "        return start_img, end_img, time_skip\n",
        "\n",
        "\n",
        "    def extract_location_from_path(self, folder_path):\n",
        "        parts = folder_path.split('/')\n",
        "        dataset_index = parts.index('Homework Dataset')\n",
        "        if 'images' in parts:\n",
        "            images_index = parts.index('images')\n",
        "            location = '/'.join(parts[dataset_index + 1 : images_index])\n",
        "        else:\n",
        "            location = '/'.join(parts[dataset_index + 1 :])\n",
        "\n",
        "        return location\n",
        "\n",
        "    def extract_year_and_month(self, image_name):\n",
        "        match = re.search(r\"(\\d{4})_(\\d{2})\", image_name.split(\"/\")[-1])\n",
        "        if match:\n",
        "            year, month = map(int, match.groups())\n",
        "            #print(f\"Extracted year: {year}, month: {month} from {image_name}\")\n",
        "            return year, month\n",
        "        else:\n",
        "            return 0, 0\n",
        "\n",
        "    def calculate_time_skip(self, start_image_name, end_image_name):\n",
        "        start_year, start_month = self.extract_year_and_month(start_image_name)\n",
        "        end_year, end_month = self.extract_year_and_month(end_image_name)\n",
        "        time_skip = (end_year - start_year) * 12 + (end_month - start_month)\n",
        "        return abs(time_skip)\n",
        "\n",
        "\n",
        "    def load_image_pairs(self):\n",
        "        image_pairs = []\n",
        "\n",
        "        # Iterate through subdirectories in the main folder\n",
        "        for dir_name in os.listdir(self.folder_path):\n",
        "            dir_path = os.path.join(self.folder_path, dir_name)\n",
        "            images_dir = os.path.join(dir_path, \"images\")\n",
        "            image_files = os.listdir(images_dir)\n",
        "\n",
        "            # Create pairs of images within the \"images\" directory\n",
        "            for i in range(len(image_files) - 1):\n",
        "                start_image = os.path.join(images_dir, image_files[i])\n",
        "                end_image = os.path.join(images_dir, image_files[i + 1])\n",
        "\n",
        "                start_year, start_month = self.extract_year_and_month(start_image)\n",
        "                end_year, end_month = self.extract_year_and_month(end_image)\n",
        "\n",
        "                # Check if the start image is not from the future compared to the end image\n",
        "                if start_year > end_year or (start_year == end_year and start_month > end_month):\n",
        "                    continue\n",
        "\n",
        "                location = self.extract_location_from_path(images_dir)\n",
        "                time_skip = self.calculate_time_skip(start_image, end_image)\n",
        "\n",
        "                #print(f\"Start Image: year {start_year} month {start_month} with location {location} from {start_image}\")\n",
        "                #print(f\"End Image: year {end_year} month {end_month} with location {location} from {end_image}\")\n",
        "                #print(f\"Time Skip: {time_skip}\")\n",
        "\n",
        "                image_pairs.append((start_image, end_image, time_skip))\n",
        "\n",
        "        return image_pairs"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomVerticalFlip(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "dataset = HomeworkDataset(\"/content/drive/MyDrive/Homework Dataset\", transform=transform)\n",
        "train_size = int(0.7 * len(dataset))\n",
        "val_size = (len(dataset) - train_size) // 2\n",
        "test_size = len(dataset) - train_size - val_size\n",
        "\n",
        "train_data, val_data, test_data = random_split(dataset, [train_size, val_size, test_size])\n",
        "\n",
        "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_data, batch_size=32, shuffle=False)\n",
        "test_loader = DataLoader(test_data, batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "id": "DahLlg3e5gj5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(CustomModel, self).__init__()\n",
        "\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.size(0), -1)  # flatten the input\n",
        "        x = self.fc1(x)\n",
        "        x = self.fc2(x)\n",
        "        x = x.view(x.size(0), 3, 128, 128)  # reshaping the output to match target\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "XcVdlj2E5nap"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model = CustomModel(input_size, hidden_size, output_size)\n",
        "model = CustomModel(49152, 1024, 49152)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "criterion = nn.MSELoss()  # Suitable for image generation\n",
        "\n",
        "#device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "#model.to(device)\n",
        "\n",
        "\n",
        "def train():\n",
        "    model.train()\n",
        "    total_train_loss = 0\n",
        "    for idx, batch in enumerate(train_loader):\n",
        "        start_img, end_img, _ = batch\n",
        "        #start_img, end_img = start_img.to(device), end_img.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(start_img)\n",
        "        assert output.shape == end_img.shape, f\"Output shape: {output.shape}, Expected shape: {end_img.shape}\"\n",
        "        loss = criterion(output, end_img)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_train_loss += loss.item()\n",
        "    avg_train_loss = total_train_loss / len(train_loader)\n",
        "    return avg_train_loss\n",
        "\n",
        "def val():\n",
        "    model.eval()\n",
        "    total_val_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for idx, batch in enumerate(val_loader):\n",
        "            start_img, end_img, _ = batch\n",
        "            #start_img, end_img = start_img.to(device), end_img.to(device)\n",
        "            output = model(start_img)\n",
        "            assert output.shape == end_img.shape, f\"Output shape: {output.shape}, Expected shape: {end_img.shape}\"\n",
        "            loss = criterion(output, end_img)\n",
        "            total_val_loss += loss.item()\n",
        "    avg_val_loss = total_val_loss / len(val_loader)\n",
        "    return avg_val_loss\n",
        "\n",
        "def run(epochs):\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        train_loss = train()\n",
        "        val_loss = val()\n",
        "\n",
        "        train_losses.append(train_loss)\n",
        "        val_losses.append(val_loss)\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{epochs} - Training Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}\")\n",
        "\n",
        "    plt.plot(range(epochs), train_losses, label=\"Training Loss\")\n",
        "    plt.plot(range(epochs), val_losses, label=\"Validation Loss\")\n",
        "    plt.legend()\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "X9ODyJ8b5qGv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}